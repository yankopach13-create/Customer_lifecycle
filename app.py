"""
–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–æ–¥—É–∫—Ç–µ.
Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç—á—ë—Ç–æ–≤ –∏–∑ Qlik –ø–æ —à–∞–±–ª–æ–Ω—É.
"""

import base64
import io
import json
import re
import streamlit as st
from openpyxl.styles import Alignment
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: —Å—Ç–æ–ª–±–µ—Ü 0 ‚Äî –∫–∞—Ç–µ–≥–æ—Ä–∏—è/–ø—Ä–æ–¥—É–∫—Ç, 1‚Äî2 ‚Äî –ø–µ—Ä–∏–æ–¥, 3 ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, 4 ‚Äî –∫–æ–¥ –∫–ª–∏–µ–Ω—Ç–∞
COL_CATEGORY = "category"
COL_PERIOD_MAIN = "period_main"
COL_PERIOD_SUB = "period_sub"
COL_QUANTITY = "quantity"
COL_CLIENT = "client_id"

# 8 –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: –ø–æ—Ä—è–¥–æ–∫ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, –Ω–∞–∑–≤–∞–Ω–∏–µ ‚Üí –æ–ø–∏—Å–∞–Ω–∏–µ
CLUSTER_8_ORDER = [
    "–ê–∫—Ç–∏–≤–Ω—ã–µ (VIP)",
    "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º",
    "–ö—Ä—É–ø–Ω—ã–µ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ",
    "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
    "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (–º–∞–ª—ã–π –æ–±—ä—ë–º)",
    "–ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
    "–†–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è –ø–æ–∫—É–ø–∫–∞",
    "–†–∞–∑–æ–≤–∞—è –ø–æ–∫—É–ø–∫–∞",
]
CLUSTER_8_DESCRIPTIONS = {
    "–ê–∫—Ç–∏–≤–Ω—ã–µ (VIP)": "–í—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º –ø–æ–∫—É–ø–æ–∫ –∏ –≤—ã—Å–æ–∫–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å: –ø–æ–∫—É–ø–∞—é—Ç —á–∞—Å—Ç–æ –∏ –º–Ω–æ–≥–æ.",
    "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º": "–í—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º –∏ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å: –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –∫—Ä—É–ø–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–∏.",
    "–ö—Ä—É–ø–Ω—ã–µ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ": "–í—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º, –Ω–æ –ø–æ–∫—É–ø–∞—é—Ç –Ω–µ –≤ –∫–∞–∂–¥—ã–π –ø–µ—Ä–∏–æ–¥: –∫—Ä—É–ø–Ω—ã–µ, –Ω–æ —Ä–µ–¥–∫–∏–µ –ø–æ–∫—É–ø–∫–∏.",
    "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å": "–°—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º –∏ —Å—Ä–µ–¥–Ω—è—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å: —É–º–µ—Ä–µ–Ω–Ω–∞—è –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å.",
    "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (–º–∞–ª—ã–π –æ–±—ä—ë–º)": "–ù–∏–∑–∫–∏–π –æ–±—ä—ë–º, –Ω–æ –ø–æ–∫—É–ø–∞—é—Ç —á–∞—Å—Ç–æ: —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–∞–ª—ã–µ –ø–æ–∫—É–ø–∫–∏.",
    "–ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å": "–ù–∏–∑–∫–∏–π –æ–±—ä—ë–º –∏ –Ω–µ–≤—ã—Å–æ–∫–∞—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å: —ç–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞–ª—ã–µ –ø–æ–∫—É–ø–∫–∏.",
    "–†–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è –ø–æ–∫—É–ø–∫–∞": "–í—ã—Å–æ–∫–∏–π –æ–±—ä—ë–º –∑–∞ –æ–¥–∏–Ω –∏–ª–∏ –¥–≤–∞ –ø–µ—Ä–∏–æ–¥–∞: —Ä–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è —Å–¥–µ–ª–∫–∞.",
    "–†–∞–∑–æ–≤–∞—è –ø–æ–∫—É–ø–∫–∞": "–ù–∏–∑–∫–∏–π –æ–±—ä—ë–º –∏ –æ–¥–Ω–∞-–¥–≤–µ –ø–æ–∫—É–ø–∫–∏: –ø–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏ –ø—Ä–æ–¥—É–∫—Ç.",
    "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏": "–í –≤—ã–±—Ä–∞–Ω–Ω–æ–º –æ–∫–Ω–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç.",
}


def _cluster_display_name(name: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç –≤—Å—ë –≤ —Å–∫–æ–±–∫–∞—Ö –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    return re.sub(r"\s*\([^)]*\)", "", name).strip() if name else name


def create_copy_button(text: str, button_label: str, key: str) -> None:
    """–°–æ–∑–¥–∞—ë—Ç –∫–Ω–æ–ø–∫—É –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞ (Clipboard API + fallback)."""
    safe_key = re.sub(r"[^a-zA-Z0-9_]", "_", str(key))
    text_json = json.dumps(text)
    html = f"""
    <div data-testid="stButton" style="width: 100%; margin: 5px 0;">
        <button id="copy_btn_{safe_key}" onclick="copyToClipboard_{safe_key}()" style="
            width: 100%;
            padding: 12px 16px;
            background: transparent !important;
            color: #fff !important;
            font-weight: 700 !important;
            border: 2px solid #adb5bd !important;
            border-radius: 8px !important;
            cursor: pointer !important;
            font-weight: 400 !important;
            font-size: 0.85rem !important;
            line-height: 1.3 !important;
            text-align: center !important;
            min-height: 72px !important;
            height: 72px !important;
            display: flex !important;
            align-items: center !important;
            justify-content: center !important;
            white-space: normal !important;
            word-wrap: break-word !important;
            overflow-wrap: break-word !important;
            box-shadow: none !important;
            transition: all 0.3s ease !important;
            margin: 0 !important;
            box-sizing: border-box !important;
            position: relative !important;
        " onmouseover="if (!this.classList.contains('copied')) {{ this.style.transform='translateY(-2px)'; this.style.boxShadow='0 2px 8px rgba(0,0,0,0.08)'; this.style.borderColor='#6c757d'; }}" onmouseout="if (!this.classList.contains('copied')) {{ this.style.transform='translateY(0)'; this.style.boxShadow='none'; this.style.borderColor='#adb5bd'; }}" onmousedown="if (!this.classList.contains('copied')) {{ this.style.transform='translateY(0)'; }}" onmouseup="if (!this.classList.contains('copied')) {{ this.style.transform='translateY(-2px)'; }}">
            <div style="display: flex; align-items: center; justify-content: center; width: 100%;">
                <p id="copy_btn_text_{safe_key}" style="margin: 0; padding: 0; font-size: 0.85rem; font-weight: 700; color: #fff; line-height: 1.3; word-wrap: break-word; overflow-wrap: break-word; white-space: normal;">{button_label}</p>
            </div>
        </button>
    </div>
    <script>
        const textToCopy_{safe_key} = {text_json};
        function copyToClipboard_{safe_key}() {{
            const text = textToCopy_{safe_key};
            const button = document.getElementById('copy_btn_{safe_key}');
            const buttonText = document.getElementById('copy_btn_text_{safe_key}');
            const originalText = buttonText.innerHTML;
            function showSuccess() {{
                button.classList.add('copied');
                button.style.background = 'linear-gradient(135deg, #4CAF50 0%, #45a049 100%)';
                button.style.borderColor = '#4CAF50';
                button.style.color = 'white';
                button.style.transform = 'scale(0.98)';
                buttonText.innerHTML = '‚úì –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ!';
                setTimeout(function() {{
                    button.classList.remove('copied');
                    button.style.background = 'transparent';
                    button.style.borderColor = '#adb5bd';
                    button.style.color = '#fff';
                    button.style.transform = 'translateY(0)';
                    buttonText.innerHTML = originalText;
                }}, 2500);
            }}
            if (navigator.clipboard && navigator.clipboard.writeText) {{
                navigator.clipboard.writeText(text).then(function() {{ showSuccess(); }}).catch(function(err) {{
                    console.error('Clipboard API error:', err);
                    fallbackCopy_{safe_key}(text, showSuccess);
                }});
            }} else {{
                fallbackCopy_{safe_key}(text, showSuccess);
            }}
        }}
        function fallbackCopy_{safe_key}(text, successCallback) {{
            const textarea = document.createElement('textarea');
            textarea.value = text;
            textarea.style.position = 'fixed';
            textarea.style.left = '-999999px';
            textarea.style.top = '-999999px';
            textarea.style.opacity = '0';
            document.body.appendChild(textarea);
            textarea.focus();
            textarea.select();
            try {{
                const successful = document.execCommand('copy');
                if (successful) {{ successCallback(); }}
                else {{ alert('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é.'); }}
            }} catch(err) {{
                console.error('Copy command error:', err);
                alert('–û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: ' + err);
            }} finally {{
                document.body.removeChild(textarea);
            }}
        }}
    </script>
    """
    components.html(html, height=85)


def create_excel_download_button(excel_bytes: bytes, filename: str, button_label: str, key: str) -> None:
    """–°–æ–∑–¥–∞—ë—Ç HTML-–∫–Ω–æ–ø–∫—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Excel (–ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ —Ä–∞–∑–º–µ—Ä–æ–º –∏ –≤–∏–∑—É–∞–ª–æ–º, –∫–∞–∫ –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ)."""
    safe_key = re.sub(r"[^a-zA-Z0-9_]", "_", str(key))
    b64 = base64.b64encode(excel_bytes).decode("ascii")
    filename_esc = json.dumps(filename)
    html = f"""
    <div style="width: 100%; margin: 0;">
        <button id="excel_btn_{safe_key}" type="button" style="
            width: 100%;
            height: 2.375rem;
            min-height: 2.375rem;
            padding: 6px 12px;
            background: transparent;
            color: white;
            font-weight: 700;
            font-size: 0.85rem;
            border: 2px solid white;
            border-radius: 6px;
            cursor: pointer;
            text-align: center;
            line-height: 1.2;
            box-sizing: border-box;
            box-shadow: 0 2px 8px rgba(0,0,0,0.2);
            transition: transform 0.15s ease, box-shadow 0.2s ease, background 0.2s ease;
            user-select: none;
        " onmouseover="this.style.transform='scale(1.02)'; this.style.boxShadow='0 4px 14px rgba(0,0,0,0.25), 0 0 0 1px rgba(255,255,255,0.15)'; this.style.background='rgba(255,255,255,0.08)';" onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 2px 8px rgba(0,0,0,0.2)'; this.style.background='transparent';" onmousedown="this.style.transform='scale(0.98)';" onmouseup="this.style.transform='scale(1.02)';" onmouseleave="this.style.transform='scale(1)';">
            {button_label}
        </button>
    </div>
    <script>
        (function() {{
            var btn = document.getElementById('excel_btn_{safe_key}');
            var b64 = {json.dumps(b64)};
            var filename = {filename_esc};
            btn.addEventListener('click', function() {{
                var dataUri = 'data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,' + b64;
                var a = document.createElement('a');
                a.href = dataUri;
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
            }});
        }})();
    </script>
    """
    components.html(html, height=46)


def _norm_client_id(ser: pd.Series) -> pd.Series:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –∫–æ–¥—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ –∫ –æ–¥–Ω–æ–º—É —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –≤–∏–¥—É (348385 –∏ 348385.0 ‚Üí –æ–¥–∏–Ω–∞–∫–æ–≤–æ)."""
    s = ser.astype(str).str.strip()
    # —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç .0 —É —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª, —á—Ç–æ–±—ã —Å–æ–≤–ø–∞–¥–∞–ª–∏ –∫–æ–¥—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    return s.str.replace(r"\.0$", "", regex=True)


def load_and_normalize(uploaded_file):
    """–ß–∏—Ç–∞–µ—Ç Excel –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º —Å—Ç–æ–ª–±—Ü–∞–º: category, period_main, period_sub, quantity, client_id."""
    if uploaded_file is None:
        return None
    raw = pd.read_excel(uploaded_file, header=0)
    # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ –ø–æ–∑–∏—Ü–∏–∏
    cols = raw.iloc[:, :5].copy()
    cols.columns = [COL_CATEGORY, COL_PERIOD_MAIN, COL_PERIOD_SUB, COL_QUANTITY, COL_CLIENT]
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ –ø–æ–ª—è–º–∏
    cols = cols.dropna(subset=[COL_PERIOD_MAIN, COL_CLIENT])
    cols[COL_QUANTITY] = pd.to_numeric(cols[COL_QUANTITY], errors="coerce").fillna(0).astype(int)
    cols[COL_CATEGORY] = cols[COL_CATEGORY].astype(str).str.strip()
    cols[COL_CLIENT] = _norm_client_id(cols[COL_CLIENT])
    return cols


def merge_and_prepare(df1, df2):
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –≥–æ—Ç–æ–≤–∏—Ç –ø–µ—Ä–∏–æ–¥, –ø–æ—Ä—è–¥–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ –∏ –∫–æ–≥–æ—Ä—Ç—É (–ø–µ—Ä–≤—ã–π –ø–µ—Ä–∏–æ–¥ –∫–ª–∏–µ–Ω—Ç–∞)."""
    df = pd.concat([df1, df2], ignore_index=True)
    df[COL_PERIOD_MAIN] = df[COL_PERIOD_MAIN].astype(str).str.strip()
    df[COL_PERIOD_SUB] = df[COL_PERIOD_SUB].astype(str).str.strip()
    # –ü–æ—Ä—è–¥–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–≥–æ—Ä—Ç—ã
    period_order = (
        df[[COL_PERIOD_MAIN, COL_PERIOD_SUB]]
        .drop_duplicates()
        .sort_values([COL_PERIOD_MAIN, COL_PERIOD_SUB])
        .reset_index(drop=True)
    )
    period_order["period_rank"] = period_order.index
    df = df.merge(
        period_order,
        on=[COL_PERIOD_MAIN, COL_PERIOD_SUB],
        how="left",
    )
    first_rank = df.groupby(COL_CLIENT)["period_rank"].min().rename("first_period_rank")
    df = df.merge(first_rank, left_on=COL_CLIENT, right_index=True, how="left")
    rank_to_period = period_order.set_index("period_rank")[[COL_PERIOD_MAIN, COL_PERIOD_SUB]]
    return df, period_order, rank_to_period, first_rank


def format_period_short(period_main, period_sub):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä–∏–æ–¥ –∫–∞–∫ 25/1, 25/2 (–≥–æ–¥/–Ω–µ–¥–µ–ª—è)."""
    pm, ps = str(period_main).strip(), str(period_sub).strip()
    year_match = re.search(r"20\d{2}|\d{4}", pm)
    year_short = year_match.group(0)[-2:] if year_match else (pm[-2:] if len(pm) >= 2 else "")
    week_match = re.search(r"\d+", ps)
    week = week_match.group(0) if week_match else ps
    return f"{year_short}/{week}" if year_short and week else f"{pm} {ps}".strip()


# –°–æ–∫—Ä–∞—â–µ–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ –¥–ª—è —Å—Ç—Ä–æ–∫–∏ ¬´–ü–æ –¥–∞–Ω–Ω—ã–º –∑–∞ —è–Ω–≤-—Ñ–µ–≤ 2025¬ª
_MONTH_ABBR = {
    "—è–Ω–≤–∞—Ä—å": "—è–Ω–≤", "—Ñ–µ–≤—Ä–∞–ª—å": "—Ñ–µ–≤", "–º–∞—Ä—Ç": "–º–∞—Ä", "–∞–ø—Ä–µ–ª—å": "–∞–ø—Ä",
    "–º–∞–π": "–º–∞–π", "–∏—é–Ω—å": "–∏—é–Ω", "–∏—é–ª—å": "–∏—é–ª", "–∞–≤–≥—É—Å—Ç": "–∞–≤–≥",
    "—Å–µ–Ω—Ç—è–±—Ä—å": "—Å–µ–Ω", "–æ–∫—Ç—è–±—Ä—å": "–æ–∫—Ç", "–Ω–æ—è–±—Ä—å": "–Ω–æ—è", "–¥–µ–∫–∞–±—Ä—å": "–¥–µ–∫",
}


def format_period_range_for_caption(cohorts_to_use, cohort_ranks, rank_to_period, k_periods, is_months):
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–¥–ø–∏—Å—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –ø–µ—Ä–∏–æ–¥–æ–≤: ¬´–ü–æ –¥–∞–Ω–Ω—ã–º –∑–∞ 1-6 –Ω–µ–¥–µ–ª—å 2025¬ª –∏–ª–∏ ¬´–ü–æ –¥–∞–Ω–Ω—ã–º –∑–∞ —è–Ω–≤-—Ñ–µ–≤ 2025¬ª.
    """
    if not cohorts_to_use or not rank_to_period.index.size:
        return ""
    r_min = min(cohort_ranks[lb] for lb in cohorts_to_use)
    r_max = max(cohort_ranks[lb] for lb in cohorts_to_use) + int(k_periods) - 1
    r_max = min(r_max, rank_to_period.index.max())
    r_min = max(r_min, rank_to_period.index.min())
    first = rank_to_period.loc[r_min]
    last = rank_to_period.loc[r_max]
    pm_f, ps_f = str(first[COL_PERIOD_MAIN]).strip(), str(first[COL_PERIOD_SUB]).strip()
    pm_l, ps_l = str(last[COL_PERIOD_MAIN]).strip(), str(last[COL_PERIOD_SUB]).strip()
    year_match = re.search(r"20\d{2}|\d{4}", pm_f)
    year = year_match.group(0) if year_match else (pm_l if re.search(r"\d{4}", pm_l) else "")
    if is_months:
        abbr = lambda s: _MONTH_ABBR.get(s.lower(), s[:3].lower() if len(s) >= 3 else s)
        part = f"{abbr(ps_f)}-{ps_l}" if ps_f != ps_l else abbr(ps_f)
        return f"–ü–æ –¥–∞–Ω–Ω—ã–º –∑–∞ {part} {year}"
    w_f = re.search(r"\d+", ps_f)
    w_l = re.search(r"\d+", ps_l)
    week_f = w_f.group(0) if w_f else ps_f
    week_l = w_l.group(0) if w_l else ps_l
    return f"–ü–æ –¥–∞–Ω–Ω—ã–º –∑–∞ {week_f}-{week_l} –Ω–µ–¥–µ–ª—å {year}"


def _html_to_plain_text(html: str) -> str:
    """–£–±–∏—Ä–∞–µ—Ç HTML-—Ç–µ–≥–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –æ—Å—Ç–∞–≤–ª—è–µ—Ç —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç."""
    if not html:
        return ""
    text = re.sub(r"<[^>]+>", " ", html)
    text = re.sub(r"&nbsp;", " ", text)
    text = re.sub(r"&amp;", "&", text)
    text = re.sub(r"&lt;", "<", text)
    text = re.sub(r"&gt;", ">", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def _strip_css_from_html(html: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –±–ª–æ–∫ <style>...</style>, —á—Ç–æ–±—ã –≤ —Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–ø–∞–¥–∞–ª–∏ —Å—Ç–∏–ª–∏."""
    if not html:
        return html
    return re.sub(r"<style[^>]*>.*?</style>", "", html, flags=re.DOTALL | re.IGNORECASE)


def build_excel_report(
    cohort_start: str,
    cohort_end: str,
    categories: list,
    k_periods: int,
    is_months: bool,
    cluster_summary: pd.DataFrame,
    cluster_comments: dict,
    lifecycle_clusters: list,
    lifecycle_table: pd.DataFrame,
    lifecycle_output_text: str,
) -> bytes:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –≤ Excel: –ª–∏—Å—Ç 1 ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Å –ø—Ä–∏–º–µ—á–∞–Ω–∏—è–º–∏ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö),
    –ª–∏—Å—Ç 2 ‚Äî —Ü–∏–∫–ª –∂–∏–∑–Ω–∏ (–∫–ª–∞—Å—Ç–µ—Ä—ã, —Ç–∞–±–ª–∏—Ü–∞, –≤—ã–≤–æ–¥ –≤ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π —è—á–µ–π–∫–µ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º).
    –ú–µ—Ç—Ä–∏–∫–∏ –≤ % –≤—ã–≤–æ–¥—è—Ç—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞.
    """
    buffer = io.BytesIO()
    period_word = "–º–µ—Å—è—Ü–µ–≤" if is_months else "–Ω–µ–¥–µ–ª—å"
    cluster_comments = cluster_comments or {}

    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        # –õ–∏—Å—Ç 1: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã + –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        params_rows = [
            ["–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç—á—ë—Ç–∞", ""],
            ["–° –∫–æ–≥–æ—Ä—Ç—ã", cohort_start],
            ["–ü–æ –∫–æ–≥–æ—Ä—Ç—É", cohort_end],
            ["–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç", ", ".join(categories) if categories else "‚Äî"],
            ["–ü–µ—Ä–∏–æ–¥ (–Ω–µ–¥–µ–ª—å/–º–µ—Å—è—Ü–µ–≤ —Å –∫–æ–≥–æ—Ä—Ç—ã)", f"{k_periods} {period_word}"],
        ]
        params_df = pd.DataFrame(params_rows)
        params_df.to_excel(writer, sheet_name="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∫–ª–∞—Å—Ç–µ—Ä—ã", index=False, header=False)

        start_row = len(params_rows) + 2
        if cluster_summary is not None and not cluster_summary.empty:
            export_cols = [c for c in ["cluster", "clients", "pct", "total_volume", "pct_volume", "avg_client_per_period", "avg_regularity"] if c in cluster_summary.columns]
            cluster_export = cluster_summary[export_cols].copy()
            # –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ Excel ‚Äî –∫–∞–∫ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ (—Å –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º –±–µ–∑ —Å–∫–æ–±–æ–∫, –∫—Ä–æ–º–µ ¬´–ò—Ç–æ–≥–æ¬ª)
            cluster_export["cluster"] = cluster_export["cluster"].apply(
                lambda x: "–ò—Ç–æ–≥–æ" if x == "–ò—Ç–æ–≥–æ" else _cluster_display_name(str(x))
            )
            # –ú–µ—Ç—Ä–∏–∫–∏ –≤ % ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤ %
            if "pct" in cluster_export.columns:
                cluster_export["pct"] = cluster_export["pct"].apply(lambda x: f"{float(x):.1f}%")
            if "pct_volume" in cluster_export.columns:
                cluster_export["pct_volume"] = cluster_export["pct_volume"].apply(lambda x: f"{float(x):.1f}%")
            col_names_ru = {
                "cluster": "–ö–ª–∞—Å—Ç–µ—Ä",
                "clients": "–ö–ª–∏–µ–Ω—Ç–æ–≤",
                "pct": "% –∫–ª–∏–µ–Ω—Ç–æ–≤",
                "total_volume": "–û–±—ä—ë–º –∑–∞ –ø–µ—Ä–∏–æ–¥",
                "pct_volume": "% –æ–±—ä—ë–º–∞",
                "avg_client_per_period": "–°—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ –ø–æ–∫—É–ø–∫–∏",
                "avg_regularity": "–†–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å",
            }
            cluster_export = cluster_export.rename(columns=col_names_ru)
            cluster_export.to_excel(writer, sheet_name="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∫–ª–∞—Å—Ç–µ—Ä—ã", index=False, startrow=start_row)

            # –ü–æ–¥ —Ç–∞–±–ª–∏—Ü–µ–π ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –≤ 3 —Å—Ç–æ–ª–±—Ü–∞—Ö (–∫–ª–∞—Å—Ç–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ, –∫—Ä–∏—Ç–µ—Ä–∏–π), —è—á–µ–π–∫–∏ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Ç–µ–∫—Å—Ç–∞
            desc_rows = []
            for cluster_name in cluster_summary["cluster"].tolist():
                if cluster_name == "–ò—Ç–æ–≥–æ":
                    continue
                comment_text = cluster_comments.get(cluster_name, "")
                if "\n\n–ö—Ä–∏—Ç–µ—Ä–∏–∏: " in comment_text:
                    desc_part, crit_part = comment_text.split("\n\n–ö—Ä–∏—Ç–µ—Ä–∏–∏: ", 1)
                    desc_rows.append((_cluster_display_name(cluster_name), desc_part.strip(), crit_part.strip()))
                else:
                    desc_rows.append((_cluster_display_name(cluster_name), comment_text.strip(), ""))
            if desc_rows:
                desc_df = pd.DataFrame(desc_rows, columns=["–ö–ª–∞—Å—Ç–µ—Ä", "–û–ø–∏—Å–∞–Ω–∏–µ", "–ö—Ä–∏—Ç–µ—Ä–∏–∏"])
                desc_start = start_row + 2 + len(cluster_export)
                desc_df.to_excel(writer, sheet_name="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∫–ª–∞—Å—Ç–µ—Ä—ã", index=False, startrow=desc_start)
                ws1 = writer.sheets["–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∫–ª–∞—Å—Ç–µ—Ä—ã"]
                for r in range(desc_start + 1, desc_start + 2 + len(desc_df)):
                    for c in range(1, 4):
                        cell = ws1.cell(row=r, column=c)
                        cell.alignment = Alignment(wrap_text=True, vertical="top")

        # –õ–∏—Å—Ç 2: —Ü–∏–∫–ª –∂–∏–∑–Ω–∏
        sheet2_name = "–¶–∏–∫–ª –∂–∏–∑–Ω–∏"
        header_rows = [
            ["–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ —è–∫–æ—Ä–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞"],
            ["–í—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏", ", ".join(lifecycle_clusters) if lifecycle_clusters else "–í—Å–µ"],
            [],
        ]
        header_df = pd.DataFrame(header_rows)
        header_df.to_excel(writer, sheet_name=sheet2_name, index=False, header=False)

        table_start = len(header_rows) + 1
        if lifecycle_table is not None and not lifecycle_table.empty:
            lifecycle_table.to_excel(writer, sheet_name=sheet2_name, index=False, startrow=table_start)

        out_start_row = table_start + (len(lifecycle_table) + 2 if lifecycle_table is not None and not lifecycle_table.empty else 0)

        # –í—ã–≤–æ–¥ –Ω–∞ –ª–∏—Å—Ç–µ –¶–∏–∫–ª –∂–∏–∑–Ω–∏ ‚Äî –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–∞—è —è—á–µ–π–∫–∞ —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Ç–µ–∫—Å—Ç–∞
        if lifecycle_output_text:
            ws2 = writer.sheets[sheet2_name]
            ws2.cell(row=out_start_row + 1, column=1, value="–í—ã–≤–æ–¥")
            out_text_cell = ws2.cell(row=out_start_row + 2, column=1, value=lifecycle_output_text)
            out_text_cell.alignment = Alignment(wrap_text=True, vertical="top")
            merge_rows = max(15, min(80, len(lifecycle_output_text) // 60))
            ws2.merge_cells(
                start_row=out_start_row + 2,
                start_column=1,
                end_row=out_start_row + 2 + merge_rows,
                end_column=6,
            )

    buffer.seek(0)
    return buffer.getvalue()


def _placeholder_excel_bytes() -> bytes:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–∞–ª–∏–¥–Ω—ã–π xlsx –¥–ª—è –∫–Ω–æ–ø–∫–∏, –∫–æ–≥–¥–∞ –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –µ—â—ë –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω."""
    buf = io.BytesIO()
    placeholder_df = pd.DataFrame([["–û—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –±–ª–æ–∫–æ–≤ ¬´–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑¬ª –∏ ¬´–¶–∏–∫–ª –∂–∏–∑–Ω–∏¬ª –Ω–∏–∂–µ."]])
    placeholder_df.to_excel(buf, sheet_name="–ò–Ω—Ñ–æ", index=False, header=False)
    buf.seek(0)
    return buf.getvalue()


def build_stacked_area(
    df_plot, x_col, value_col, stack_col, title, value_label,
    x_order=None, show_title=True, xaxis_title=None, xaxis_side="bottom",
    margin_override=None,
):
    """–°—Ç—Ä–æ–∏—Ç —Å—Ç–µ–∫–æ–≤—É—é –¥–∏–∞–≥—Ä–∞–º–º—É —Å –æ–±–ª–∞—Å—Ç—è–º–∏ (stacked area)."""
    if df_plot.empty:
        fig = go.Figure()
        fig.add_annotation(text="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        fig.update_layout(title=dict(text=title or "", x=0.5, xanchor="center") if show_title and title else {})
        return fig
    x_vals = x_order if x_order is not None else df_plot[x_col].unique().tolist()
    stacks = df_plot[stack_col].unique().tolist()
    fig = go.Figure()
    for s in stacks:
        sub = df_plot[df_plot[stack_col] == s]
        sub = sub.set_index(x_col)[value_col].reindex(x_vals).fillna(0)
        fig.add_trace(
            go.Scatter(
                x=x_vals,
                y=sub.tolist(),
                name=str(s),
                mode="lines",
                fill="tonexty",
                stackgroup="one",
                line=dict(width=0.5),
            )
        )
    margin = margin_override if margin_override is not None else dict(t=60, b=50)
    layout_kw = dict(
        hovermode="x unified",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=margin,
        template="plotly_white",
        yaxis_title=value_label,
    )
    if show_title and title:
        layout_kw["title"] = dict(text=title, x=0.5, xanchor="center")
    if xaxis_title is not None:
        layout_kw["xaxis_title"] = xaxis_title
        layout_kw["xaxis"] = dict(side=xaxis_side)
    else:
        layout_kw["xaxis_title"] = x_col
    fig.update_layout(**layout_kw)
    return fig


# –í—ã—Å–æ—Ç–∞ –∫–∞–∂–¥–æ–≥–æ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞ –≤ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π —Ñ–∏–≥—É—Ä–µ (–ø–∏–∫—Å–µ–ª–∏)
COMBINED_CHART_ROW_HEIGHT = 260


def build_combined_two_charts(
    clients_by_period,
    qty_by_period,
    x_col,
    period_labels_short,
    stack_col,
    add_total=False,
    clients_total_values=None,
    qty_total_values=None,
):
    """
    –°—Ç—Ä–æ–∏—Ç –æ–¥–Ω—É —Ñ–∏–≥—É—Ä—É —Å –¥–≤—É–º—è –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏ (–æ–±—â–∞—è –æ—Å—å X).
    –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ü–≤–µ—Ç–∞ –≤ –æ–±–æ–∏—Ö –≥—Ä–∞—Ñ–∏–∫–∞—Ö.
    –ü—Ä–∏ add_total –∏ 2+ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–µ—Ä–∏—è ¬´–ò—Ç–æ–≥–æ¬ª (–æ–¥–∏–Ω —Ü–≤–µ—Ç –≤ –ª–µ–≥–µ–Ω–¥–µ).
    """
    x_vals = period_labels_short
    if clients_by_period.empty and qty_by_period.empty:
        fig = go.Figure()
        fig.add_annotation(text="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig

    stacks_cl = clients_by_period[stack_col].unique().tolist() if not clients_by_period.empty else []
    stacks_q = qty_by_period[stack_col].unique().tolist() if not qty_by_period.empty else []
    all_stacks = list(dict.fromkeys(stacks_cl + stacks_q))
    if add_total:
        all_stacks = ["–ò—Ç–æ–≥–æ"] + all_stacks
    palette = px.colors.qualitative.Plotly
    color_map = {s: palette[i % len(palette)] for i, s in enumerate(all_stacks)}

    fig = make_subplots(
        rows=2,
        cols=1,
        shared_xaxes=True,
        vertical_spacing=0.04,
        row_heights=[1, 1],
        subplot_titles=("", ""),
    )

    # –í–µ—Ä—Ö–Ω–∏–π –≥—Ä–∞—Ñ–∏–∫: –∫–ª–∏–µ–Ω—Ç—ã (—Å–Ω–∞—á–∞–ª–∞ —Å—Ç–µ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, –∑–∞—Ç–µ–º –ª–∏–Ω–∏—è –ò—Ç–æ–≥–æ –ø–æ–≤–µ—Ä—Ö)
    if not clients_by_period.empty:
        for s in stacks_cl:
            sub = clients_by_period[clients_by_period[stack_col] == s]
            sub = sub.set_index(x_col)["clients_count"].reindex(x_vals).fillna(0)
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=sub.tolist(),
                    name=str(s),
                    mode="lines",
                    fill="tonexty",
                    stackgroup="one",
                    line=dict(width=0.5, color=color_map.get(s, None)),
                ),
                row=1,
                col=1,
            )
        if add_total and clients_total_values is not None:
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=list(clients_total_values),
                    name="–ò—Ç–æ–≥–æ",
                    mode="lines",
                    line=dict(width=1.5, color=color_map.get("–ò—Ç–æ–≥–æ", "#636EFA"), dash="dash"),
                ),
                row=1,
                col=1,
            )

    # –ù–∏–∂–Ω–∏–π –≥—Ä–∞—Ñ–∏–∫: —Ç–æ–≤–∞—Ä (—Ç–µ –∂–µ —Ü–≤–µ—Ç–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º), –ª–µ–≥–µ–Ω–¥—É –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º
    if not qty_by_period.empty:
        for s in stacks_q:
            sub = qty_by_period[qty_by_period[stack_col] == s]
            sub = sub.set_index(x_col)[COL_QUANTITY].reindex(x_vals).fillna(0)
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=sub.tolist(),
                    name=str(s),
                    mode="lines",
                    fill="tonexty",
                    stackgroup="two",
                    line=dict(width=0.5, color=color_map.get(s, None)),
                    showlegend=False,
                ),
                row=2,
                col=1,
            )
        if add_total and qty_total_values is not None:
            fig.add_trace(
                go.Scatter(
                    x=x_vals,
                    y=list(qty_total_values),
                    name="–ò—Ç–æ–≥–æ",
                    mode="lines",
                    line=dict(width=1.5, color=color_map.get("–ò—Ç–æ–≥–æ", "#636EFA"), dash="dash"),
                    showlegend=False,
                ),
                row=2,
                col=1,
            )

    total_height = COMBINED_CHART_ROW_HEIGHT * 2
    fig.update_layout(
        height=total_height,
        hovermode="x unified",
        template="plotly_white",
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(t=40, b=40, l=80, r=40),
        hoverlabel=dict(
            namelength=-1,
            font=dict(size=12, color="black"),
            bgcolor="white",
            bordercolor="gray",
        ),
    )
    fig.update_xaxes(title_text="", side="top", row=1, col=1)
    fig.update_xaxes(title_text="", row=2, col=1)
    # –ü–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π Y —Å–ª–µ–≤–∞ –æ—Ç –≥—Ä–∞—Ñ–∏–∫–∞
    fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤", row=1, col=1, side="left")
    fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–∞", row=2, col=1, side="left")
    fig.update_xaxes(showspikes=True, spikemode="across+marker", spikecolor="gray", spikethickness=1)
    return fig


# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–ª—è Streamlit Cloud) ---
st.set_page_config(
    page_title="–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–æ–¥—É–∫—Ç–µ",
    page_icon="üîÑ",
    layout="wide",
)

# --- –ó–∞–≥–æ–ª–æ–≤–æ–∫ (–æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞) ---
st.title("üîÑ –¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–æ–¥—É–∫—Ç–µ")
st.divider()

# --- –î–≤–µ –∫–æ–ª–æ–Ω–∫–∏: –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–ª–µ–≤–∞, —à–∞–±–ª–æ–Ω –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫ —Å–ø—Ä–∞–≤–∞ ---
col_instruction, col_template = st.columns([1, 1])

with col_instruction:
    st.subheader("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∫ –∑–∞–≥—Ä—É–∑–∫–µ 1 –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    st.markdown("""
    1. –ó–∞–π–¥–∏—Ç–µ –≤ Qlik, —Ä–∞–∑–¥–µ–ª ¬´–ê–Ω–∞–ª–∏–∑ —á–µ–∫–æ–≤¬ª, –ª–∏—Å—Ç ¬´–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä¬ª.
    2. –û—Ç–±–µ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã/–∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ –æ–¥–Ω–æ–º –∏–∑ —Ä–∞–∑—Ä–µ–∑–æ–≤ –ì—Ä—É–ø–ø–∞1 / –ì—Ä—É–ø–ø–∞2 / –ì—Ä—É–ø–ø–∞3 / –ì—Ä—É–ø–ø–∞4.
    3. –û—Ç–±–µ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø–µ—Ä–∏–æ–¥ –∏ —Ä–∞–∑—Ä–µ–∑ (–≥–æ–¥‚Äì–º–µ—Å—è—Ü –∏–ª–∏ –≥–æ–¥‚Äì–Ω–µ–¥–µ–ª—è).
    4. –í—ã–≤–µ–¥–∏—Ç–µ –æ—Ç—á—ë—Ç –ø–æ —à–∞–±–ª–æ–Ω—É —Å–ø—Ä–∞–≤–∞.
    5. –°–∫–∞—á–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –≤ Qlik –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤ —è—á–µ–π–∫—É —Å–ø—Ä–∞–≤–∞.
    """)
    st.markdown("---")
    st.subheader("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –∫ –∑–∞–≥—Ä—É–∑–∫–µ 2 –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    st.markdown("""
    1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –ª–∏—Å—Ç ¬´–ü—Ä–æ–¥–∞–∂–∏¬ª –∏ –æ—Ç–±–µ—Ä–∏—Ç–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –∏ –ø—Ä–æ–¥—É–∫—Ç–∞/–∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    2. –í—ã–±–µ—Ä–∏—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –≤—ã–≤–µ–¥–∏—Ç–µ –æ—Ç—á—ë—Ç –ø–æ —à–∞–±–ª–æ–Ω—É —Å–ø—Ä–∞–≤–∞ –Ω–∞ –ª–∏—Å—Ç–µ ¬´–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä¬ª.
    3. –°–∫–∞—á–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –≤ Qlik –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤ —è—á–µ–π–∫—É —Å–ø—Ä–∞–≤–∞.
    """)

with col_template:
    st.subheader("üìã –®–∞–±–ª–æ–Ω –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Qlik")
    try:
        st.image("qlik_template_categories.png", use_container_width=True)
    except FileNotFoundError:
        st.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª `qlik_template_categories.png` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞.")
    st.markdown("---")
    st.caption("–î–æ–∫—É–º–µ–Ω—Ç 1 ‚Äî –≤—ã–≥—Ä—É–∑–∫–∞ –∏–∑ –ª–∏—Å—Ç–∞ ¬´–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä¬ª:")
    uploaded_file_1 = st.file_uploader(
        "–î–æ–∫—É–º–µ–Ω—Ç 1",
        type=["xlsx", "xls"],
        key="qlik_upload_1",
        label_visibility="collapsed",
    )
    st.caption("–î–æ–∫—É–º–µ–Ω—Ç 2 ‚Äî –≤—ã–≥—Ä—É–∑–∫–∞ –ø–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    uploaded_file_2 = st.file_uploader(
        "–î–æ–∫—É–º–µ–Ω—Ç 2",
        type=["xlsx", "xls"],
        key="qlik_upload_2",
        label_visibility="collapsed",
    )

# --- –ë–ª–æ–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞—Å—á—ë—Ç–æ–≤ (–≥—Ä–∞—Ñ–∏–∫–∏) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±–æ–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ---
if uploaded_file_1 and uploaded_file_2:
    st.divider()
    try:
        df1 = load_and_normalize(uploaded_file_1)
        df2 = load_and_normalize(uploaded_file_2)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")
        df1 = df2 = None

    if df1 is not None and df2 is not None and not df1.empty and not df2.empty:
        had_excel_bytes = "excel_report_bytes" in st.session_state
        categories_from_doc1 = sorted(df1[COL_CATEGORY].dropna().unique().tolist())
        category_label = ", ".join(categories_from_doc1) if categories_from_doc1 else "‚Äî"
        st.markdown(f"### –Ø–∫–æ—Ä–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç –∫–æ–≥–æ—Ä—Ç: :violet[{category_label}]")

        df, period_order, rank_to_period, _ = merge_and_prepare(df1, df2)
        period_labels_short = [
            format_period_short(row[COL_PERIOD_MAIN], row[COL_PERIOD_SUB])
            for _, row in period_order[[COL_PERIOD_MAIN, COL_PERIOD_SUB]].iterrows()
        ]
        period_rank_to_short = dict(zip(period_order["period_rank"], period_labels_short))
        categories_from_doc2 = sorted(df2[COL_CATEGORY].dropna().unique().tolist())
        categories_from_doc1_set = set(categories_from_doc1)
        # –í —Å–ø–∏—Å–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ 1 (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–∞—è), –ø–æ—Ç–æ–º –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ 2 (–¥—Ä—É–≥–∏–µ)
        all_categories = categories_from_doc1 + [c for c in categories_from_doc2 if c not in categories_from_doc1_set]
        # –ö–æ–≥–æ—Ä—Ç—ã —Å –ø–æ–¥–ø–∏—Å—å—é –≤–∏–¥–∞ "2025/01 (N –∫–ª–∏–µ–Ω—Ç–æ–≤)"
        cohort_options = []
        for r in sorted(rank_to_period.index):
            row = rank_to_period.loc[r]
            pm, ps = str(row[COL_PERIOD_MAIN]).strip(), str(row[COL_PERIOD_SUB]).strip()
            short = period_labels_short[r] if r < len(period_labels_short) else f"{pm} {ps}"
            n_clients = df1[(df1[COL_PERIOD_MAIN].astype(str).str.strip() == pm) & (df1[COL_PERIOD_SUB].astype(str).str.strip() == ps)][COL_CLIENT].nunique()
            label = f"{short} ({n_clients} –∫–ª–∏–µ–Ω—Ç–æ–≤)"
            cohort_options.append((r, label))
        cohort_labels = [lb for _, lb in cohort_options]
        cohort_ranks = {lb: r for r, lb in cohort_options}

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å period_rank –¥–ª—è –±–ª–æ–∫–æ–≤ –Ω–∏–∂–µ (–∫–ª–∞—Å—Ç–µ—Ä—ã, —Ü–∏–∫–ª –∂–∏–∑–Ω–∏, –ø—Ä–æ–¥–∞–∂–∏)
        df1_norm = df1.copy()
        df1_norm[COL_PERIOD_MAIN] = df1_norm[COL_PERIOD_MAIN].astype(str).str.strip()
        df1_norm[COL_PERIOD_SUB] = df1_norm[COL_PERIOD_SUB].astype(str).str.strip()
        df2_norm = df2.copy()
        df2_norm[COL_PERIOD_MAIN] = df2_norm[COL_PERIOD_MAIN].astype(str).str.strip()
        df2_norm[COL_PERIOD_SUB] = df2_norm[COL_PERIOD_SUB].astype(str).str.strip()
        df1_with_period = df1_norm.merge(
            period_order[[COL_PERIOD_MAIN, COL_PERIOD_SUB, "period_rank"]],
            on=[COL_PERIOD_MAIN, COL_PERIOD_SUB],
            how="left",
        )
        df1_with_period["period_label_short"] = df1_with_period["period_rank"].map(period_rank_to_short)
        df2_with_period = df2_norm.merge(
            period_order[[COL_PERIOD_MAIN, COL_PERIOD_SUB, "period_rank"]],
            on=[COL_PERIOD_MAIN, COL_PERIOD_SUB],
            how="left",
        )
        df2_with_period["period_label_short"] = df2_with_period["period_rank"].map(period_rank_to_short)
        df2_with_period["_client_norm"] = _norm_client_id(df2_with_period[COL_CLIENT])
        df1_with_period["_client_norm"] = _norm_client_id(df1_with_period[COL_CLIENT])

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–µ—Ä–∏–æ–¥–∞ –ø–æ –¥–∞–Ω–Ω—ã–º (–Ω–µ–¥–µ–ª–∏ –∏–ª–∏ –º–µ—Å—è—Ü—ã) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–æ –≤—Å–µ—Ö –±–ª–æ–∫–∞—Ö
        period_sub_str = period_order[COL_PERIOD_SUB].astype(str).str.lower()
        is_months = period_sub_str.str.contains(r"—è–Ω–≤|—Ñ–µ–≤|–º–∞—Ä|–∞–ø—Ä|–º–∞–π|–∏—é–Ω|–∏—é–ª|–∞–≤–≥|—Å–µ–Ω|–æ–∫—Ç|–Ω–æ—è|–¥–µ–∫", regex=True).any()
        period_word = "–º–µ—Å—è—Ü–µ–≤" if is_months else "–Ω–µ–¥–µ–ª—å"

        # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç—á—ë—Ç–∞ (–ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ –≤—Å–µ–º –±–ª–æ–∫–∞–º) ---
        st.divider()
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç—á—ë—Ç–∞")
        # –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –∫–Ω–æ–ø–∫—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤–≤–µ—Ä—Ö, —á—Ç–æ–±—ã –Ω–∏–∑ —Å–æ–≤–ø–∞–¥–∞–ª —Å —Å–µ–ª–µ–∫—Ç–æ–º ¬´–ü–æ –∫–æ–≥–æ—Ä—Ç—É¬ª
        st.markdown(
            """
            <style>
            div[data-testid="column"]:has(iframe[height="46"]) {
                margin-top: 22px !important;
            }
            </style>
            """,
            unsafe_allow_html=True,
        )
        # –ü–µ—Ä–≤—ã–π —Ä—è–¥: [–° –∫–æ–≥–æ—Ä—Ç—ã | –ü–æ –∫–æ–≥–æ—Ä—Ç—É] | –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç (—É–∂–µ) | –ù–µ–¥–µ–ª—å/–º–µ—Å—è—Ü–µ–≤
        r1_c1, r1_c2, r1_c3 = st.columns([1.2, 0.7, 1])
        with r1_c1:
            sub_left, sub_right = st.columns(2)
            with sub_left:
                cohort_start_global = st.selectbox(
                    "–° –∫–æ–≥–æ—Ä—Ç—ã",
                    options=cohort_labels,
                    index=0,
                    key="report_cohort_start",
                )
            with sub_right:
                cohort_end_global = st.selectbox(
                    "–ü–æ –∫–æ–≥–æ—Ä—Ç—É",
                    options=cohort_labels,
                    index=0,
                    key="report_cohort_end",
                )
        with r1_c2:
            selected_categories_global = st.multiselect(
                "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç",
                options=all_categories,
                default=[],
                key="report_categories",
                help="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, —Ü–∏–∫–ª–∞ –∂–∏–∑–Ω–∏ –∏ —Ä–∞—Å—á—ë—Ç–∞ –ø—Ä–æ–¥–∞–∂ –Ω–∞ –æ–±—ä—ë–º —è–∫–æ—Ä–Ω–æ–≥–æ.",
            )
        with r1_c3:
            k_periods_global = st.number_input(
                "–ù–µ–¥–µ–ª—å/–º–µ—Å—è—Ü–µ–≤ —Å –ø–æ–∫—É–ø–∫–∏ —è–∫–æ—Ä–Ω–æ–≥–æ (–≤–∫–ª—é—á–∞—è –ø–µ—Ä–∏–æ–¥ –∫–æ–≥–æ—Ä—Ç—ã)",
                min_value=1,
                value=5,
                step=1,
                key="report_k_periods",
            )
        # –í—Ç–æ—Ä–æ–π —Ä—è–¥: –ø—É—Å—Ç–æ | –ø—É—Å—Ç–æ | –ö–Ω–æ–ø–∫–∞
        r2_c1, r2_c2, r2_c3 = st.columns([1.2, 0.7, 1])
        with r2_c1:
            pass
        with r2_c2:
            pass
        with r2_c3:
            excel_data = st.session_state.get("excel_report_bytes") or _placeholder_excel_bytes()
            report_filename = st.session_state.get("excel_report_filename", "CLF_report.xlsx")
            create_excel_download_button(
                excel_data,
                report_filename,
                "–°–∫–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –≤ Excel",
                "download_full_report",
            )

        idx_start_c = cohort_labels.index(cohort_start_global)
        idx_end_c = cohort_labels.index(cohort_end_global)
        if idx_start_c <= idx_end_c:
            cohorts_to_use_c = cohort_labels[idx_start_c : idx_end_c + 1]
        else:
            cohorts_to_use_c = cohort_labels[idx_end_c : idx_start_c + 1]
        selected_categories_cluster = selected_categories_global
        k_periods_cluster = k_periods_global

        # --- –ë–ª–æ–∫ ¬´–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑¬ª (–±–µ–∑ —Å–≤–æ–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏–∑ ¬´–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç—á—ë—Ç–∞¬ª) ---
        st.divider()
        st.subheader("–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        st.caption("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –æ–±—ä—ë–º—É –ø–æ–∫—É–ø–æ–∫ –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –ø–æ–∫—É–ø–æ–∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ –≤ –ø–µ—Ä–≤—ã–µ K –ø–µ—Ä–∏–æ–¥–æ–≤ –ø–æ—Å–ª–µ –∫–æ–≥–æ—Ä—Ç—ã.")

        if not cohorts_to_use_c:
            st.caption("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –∫–æ–≥–æ—Ä—Ç—É –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –≤—ã—à–µ.")
        elif not selected_categories_cluster:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.")
        else:
            # –ö–ª–∏–µ–Ω—Ç—ã –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π id): –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É 1 (—è–∫–æ—Ä–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç –∫–æ–≥–æ—Ä—Ç)
            cohort_clients_c = set()
            for lb in cohorts_to_use_c:
                r = cohort_ranks[lb]
                pm, ps = rank_to_period.loc[r, COL_PERIOD_MAIN], rank_to_period.loc[r, COL_PERIOD_SUB]
                pm, ps = str(pm).strip(), str(ps).strip()
                clients_r = df1[
                    (df1[COL_PERIOD_MAIN].astype(str).str.strip() == pm)
                    & (df1[COL_PERIOD_SUB].astype(str).str.strip() == ps)
                ][COL_CLIENT]
                cohort_clients_c.update(_norm_client_id(clients_r).tolist())

            if not cohort_clients_c:
                st.info("–í –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç–∞—Ö –Ω–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ (–ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É 1).")
            else:
                # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ ‚Äî –µ–≥–æ –ø–µ—Ä–∏–æ–¥ –∫–æ–≥–æ—Ä—Ç—ã (min period_rank –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É 1)
                df1_cr = df1_with_period.copy()
                df1_cr["_client_norm"] = _norm_client_id(df1_cr[COL_CLIENT])
                df1_cr = df1_cr[df1_cr["_client_norm"].isin(cohort_clients_c)]
                client_cohort_rank = df1_cr.groupby("_client_norm")["period_rank"].min()

                # –°–∫–æ–ª—å–∫–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏—è (–¥–ª—è –ø–æ–∑–¥–Ω–∏—Ö –∫–æ–≥–æ—Ä—Ç –æ–∫–Ω–æ –º–æ–∂–µ—Ç —É–ø–∏—Ä–∞—Ç—å—Å—è –≤ –∫–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö)
                max_rank = int(period_order["period_rank"].max())
                k_int = int(k_periods_cluster)
                available_periods = (max_rank - client_cohort_rank + 1).clip(lower=0, upper=k_int).astype(int)

                # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–∫—É–ø–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ 1 –∏/–∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ 2
                selected_in_doc1_c = [c for c in selected_categories_cluster if c in categories_from_doc1_set]
                selected_in_doc2_c = [c for c in selected_categories_cluster if c in set(categories_from_doc2)]

                def _filter_to_dynamic_window(df_src: pd.DataFrame) -> pd.DataFrame:
                    """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –∫–æ–≥–æ—Ä—Ç—ã –≤ –æ–∫–Ω–µ [cohort_rank, cohort_rank + K)."""
                    tmp = df_src.copy()
                    tmp["_client_norm"] = _norm_client_id(tmp[COL_CLIENT])
                    tmp = tmp[tmp["_client_norm"].isin(cohort_clients_c)]
                    r0 = tmp["_client_norm"].map(client_cohort_rank)
                    delta = tmp["period_rank"] - r0
                    mask = delta.notna() & tmp["period_rank"].notna() & (delta >= 0) & (delta < k_int)
                    return tmp.loc[mask, ["_client_norm", "period_rank", COL_QUANTITY]]

                parts_p = []
                if selected_in_doc1_c:
                    parts_p.append(
                        _filter_to_dynamic_window(
                            df1_with_period[df1_with_period[COL_CATEGORY].isin(selected_in_doc1_c)]
                        )
                    )
                if selected_in_doc2_c:
                    parts_p.append(
                        _filter_to_dynamic_window(
                            df2_with_period[df2_with_period[COL_CATEGORY].isin(selected_in_doc2_c)]
                        )
                    )

                if parts_p:
                    df_p = pd.concat(parts_p, ignore_index=True)
                else:
                    df_p = pd.DataFrame(columns=["_client_norm", "period_rank", COL_QUANTITY])

                # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∏–µ–Ω—Ç—É: –æ–±—ä—ë–º –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å (–¥–æ–ª—è –ø–µ—Ä–∏–æ–¥–æ–≤ —Å –ø–æ–∫—É–ø–∫–æ–π)
                per_client = pd.DataFrame({"client_id": sorted(cohort_clients_c)})
                per_client["cohort_rank"] = per_client["client_id"].map(client_cohort_rank).astype("float")
                per_client["available_periods"] = per_client["client_id"].map(available_periods).fillna(k_int).astype(int)

                if not df_p.empty:
                    agg = (
                        df_p.groupby("_client_norm")
                        .agg(
                            volume=(COL_QUANTITY, "sum"),
                            active_periods=("period_rank", "nunique"),
                        )
                        .reset_index()
                        .rename(columns={"_client_norm": "client_id"})
                    )
                    per_client = per_client.merge(agg, on="client_id", how="left")
                per_client["volume"] = per_client["volume"].fillna(0).astype(int)
                per_client["active_periods"] = per_client["active_periods"].fillna(0).astype(int)
                denom = per_client["available_periods"].replace(0, 1)
                per_client["regularity"] = (per_client["active_periods"] / denom).clip(0, 1).astype(float)

                # –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ–¥–Ω–æ–º—É –∏–∑ 8 –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ –æ–±—ä—ë–º—É –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏ (–ø—Ä–∞–≤–∏–ª–∞ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º)
                per_client["cluster"] = "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"
                df_fit = per_client[per_client["volume"] > 0].copy()
                v33_val = v67_val = 0.0
                if not df_fit.empty:
                    v33_val = float(df_fit["volume"].quantile(1 / 3))
                    v67_val = float(df_fit["volume"].quantile(2 / 3))
                    v33 = v33_val
                    v67 = v67_val
                    r33 = 1 / 3
                    r67 = 2 / 3

                    def _assign_cluster(row):
                        v, r = row["volume"], row["regularity"]
                        if v >= v67:
                            if r >= r67:
                                return "–ê–∫—Ç–∏–≤–Ω—ã–µ (VIP)"
                            if r >= r33:
                                return "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º"
                            return "–†–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è –ø–æ–∫—É–ø–∫–∞"
                        if v >= v33:
                            if r >= r67:
                                return "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                            if r >= r33:
                                return "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                            return "–ö—Ä—É–ø–Ω—ã–µ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ"
                        if r >= r67:
                            return "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (–º–∞–ª—ã–π –æ–±—ä—ë–º)"
                        if r >= r33:
                            return "–ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                        return "–†–∞–∑–æ–≤–∞—è –ø–æ–∫—É–ø–∫–∞"

                    df_fit["cluster"] = df_fit.apply(_assign_cluster, axis=1)
                    per_client = per_client.merge(df_fit[["client_id", "cluster"]], on="client_id", how="left", suffixes=("", "_fit"))
                    per_client["cluster"] = per_client["cluster_fit"].fillna(per_client["cluster"])
                    per_client = per_client.drop(columns=["cluster_fit"], errors="ignore")

                total_clients = len(per_client)
                k_int_cluster = int(k_periods_cluster)
                period_unit = "–º–µ—Å—è—Ü" if is_months else "–Ω–µ–¥–µ–ª—é"
                summary = (
                    per_client.groupby("cluster", dropna=False)
                    .agg(
                        clients=("client_id", "count"),
                        pct=("client_id", lambda s: 100.0 * len(s) / total_clients if total_clients else 0.0),
                        total_volume=("volume", "sum"),
                        active_periods_sum=("active_periods", "sum"),
                        avg_regularity=("regularity", "mean"),
                    )
                    .reset_index()
                )
                # –°—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –Ω–µ–¥–µ–ª—é/–º–µ—Å—è—Ü –ø–æ–∫—É–ø–∫–∏ (–¥–µ–ª–∏–º –Ω–∞ —á–∏—Å–ª–æ –ø–µ—Ä–∏–æ–¥–æ–≤ —Å –ø–æ–∫—É–ø–∫–æ–π, –∞ –Ω–µ –Ω–∞ K)
                summary["avg_client_per_period"] = (
                    (summary["total_volume"] / summary["active_periods_sum"].replace(0, 1)).round(2)
                )
                # –í—Å–µ–≥–¥–∞ 8 –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ + –ù–µ –ø–æ–∫—É–ø–∞–ª–∏; –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ ‚Äî 0
                for c in CLUSTER_8_ORDER:
                    if c not in summary["cluster"].values:
                        summary = pd.concat(
                            [
                                summary,
                                pd.DataFrame(
                                    [{
                                        "cluster": c,
                                        "clients": 0,
                                        "pct": 0.0,
                                        "total_volume": 0,
                                        "active_periods_sum": 0,
                                        "avg_regularity": 0.0,
                                        "avg_client_per_period": 0.0,
                                    }]
                                ),
                            ],
                            ignore_index=True,
                        )
                if "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏" not in summary["cluster"].values:
                    summary = pd.concat(
                        [
                            summary,
                                pd.DataFrame(
                                    [{
                                        "cluster": "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏",
                                        "clients": 0,
                                        "pct": 0.0,
                                        "total_volume": 0,
                                        "active_periods_sum": 0,
                                        "avg_regularity": 0.0,
                                        "avg_client_per_period": 0.0,
                                    }]
                                ),
                        ],
                        ignore_index=True,
                    )
                # –ü–æ—Ä—è–¥–æ–∫: –ø–æ –æ–±—ä—ë–º—É –∑–∞ –ø–µ—Ä–∏–æ–¥ –æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É, –Ω—É–ª–µ–≤—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ –∫–æ–Ω—Ü–µ
                summary = summary.sort_values("total_volume", ascending=False).reset_index(drop=True)

                total_volume_all = per_client["volume"].sum()
                total_active_periods_all = per_client["active_periods"].sum()
                avg_client_per_period_all = (
                    total_volume_all / total_active_periods_all if total_active_periods_all else 0
                )
                avg_regularity_all = per_client["regularity"].mean()
                row_–∏—Ç–æ–≥–æ = pd.DataFrame(
                    [{
                        "cluster": "–ò—Ç–æ–≥–æ",
                        "clients": total_clients,
                        "pct": 100.0,
                        "total_volume": int(total_volume_all),
                        "avg_client_per_period": round(avg_client_per_period_all, 2),
                        "avg_regularity": round(avg_regularity_all, 3),
                    }]
                )
                summary = pd.concat([row_–∏—Ç–æ–≥–æ, summary], ignore_index=True)
                summary["total_volume"] = summary["total_volume"].astype(int)
                # –î–æ–ª—è –æ–±—ä—ë–º–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä—É –æ—Ç –æ–±—â–µ–≥–æ –æ–±—ä—ë–º–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ (%)
                denom_vol = total_volume_all if total_volume_all else 1
                summary["pct_volume"] = (100.0 * summary["total_volume"] / denom_vol).round(1)
                summary["pct_volume_fmt"] = summary["pct_volume"].astype(str) + "%"

                st.session_state["report_cluster_summary"] = summary.copy()

                col_cluster = "–ö–ª–∞—Å—Ç–µ—Ä"
                col_volume = "–û–±—ä—ë–º –ø—Ä–æ–¥—É–∫—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥"
                col_pct_volume = "% –æ–±—ä—ë–º–∞"
                col_avg_client = f"–°—Ä–µ–¥–Ω–∏–π –æ–±—ä—ë–º –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞ –≤ {period_unit} –ø–æ–∫—É–ø–∫–∏"
                period_word_plural = "–º–µ—Å—è—Ü–µ–≤" if is_months else "–Ω–µ–¥–µ–ª—å"
                days_per_period = 30 if is_months else 7
                summary["pct_fmt"] = summary["pct"].round(1).astype(str) + "%"

                def _criteria_text(name: str, v33: float, v67: float, k: int, is_m: bool) -> str:
                    v33s = f"{v33:.0f}" if v33 == int(v33) else f"{v33:.1f}"
                    v67s = f"{v67:.0f}" if v67 == int(v67) else f"{v67:.1f}"
                    pw = "–º–µ—Å—è—Ü–µ–≤" if is_m else "–Ω–µ–¥–µ–ª—å"
                    dp = 30 if is_m else 7
                    n33 = max(1, round(1 / 3 * k))
                    n67 = max(1, round(2 / 3 * k))

                    def _days(ratio: float) -> str:
                        if ratio <= 0:
                            return "‚Äî"
                        d = round(dp / ratio)
                        return f"{max(1, int(d))} –¥–Ω."

                    if name == "–ê–∫—Ç–∏–≤–Ω—ã–µ (VIP)":
                        return f"–û–±—ä—ë–º ‚â• {v67s} –µ–¥. (–≤–µ—Ä—Ö–Ω—è—è —Ç—Ä–µ—Ç—å) –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ —Ä–µ–∂–µ {n67} {pw} –∏–∑ {k} (67%). –ü—Ä–∏—Ö–æ–¥—è—Ç –Ω–µ —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(2/3)}."
                    if name == "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º":
                        return f"–û–±—ä—ë–º ‚â• {v67s} –µ–¥. –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ {n33}‚Äì{n67} {pw} –∏–∑ {k} (33‚Äì67%). –ü—Ä–∏—Ö–æ–¥—è—Ç –≤ —Å—Ä–µ–¥–Ω–µ–º –∫–∞–∂–¥—ã–µ {_days(0.5)}‚Äì{_days(1/3)}."
                    if name == "–†–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è –ø–æ–∫—É–ø–∫–∞":
                        return f"–û–±—ä—ë–º ‚â• {v67s} –µ–¥. –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∂–µ {n33} {pw} –∏–∑ {k} (<33%). –ü—Ä–∏—Ö–æ–¥—è—Ç —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(0.33)}."
                    if name == "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å":
                        return f"–û–±—ä—ë–º {v33s}‚Äì{v67s} –µ–¥. (—Å—Ä–µ–¥–Ω—è—è —Ç—Ä–µ—Ç—å) –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ —Ä–µ–∂–µ {n33} {pw} –∏–∑ {k} (33%). –ü—Ä–∏—Ö–æ–¥—è—Ç –Ω–µ —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(1/3)}."
                    if name == "–ö—Ä—É–ø–Ω—ã–µ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ":
                        return f"–û–±—ä—ë–º {v33s}‚Äì{v67s} –µ–¥. –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∂–µ {n33} {pw} –∏–∑ {k} (<33%). –ü—Ä–∏—Ö–æ–¥—è—Ç —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(0.33)}."
                    if name == "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (–º–∞–ª—ã–π –æ–±—ä—ë–º)":
                        return f"–û–±—ä—ë–º < {v33s} –µ–¥. (–Ω–∏–∂–Ω—è—è —Ç—Ä–µ—Ç—å) –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ —Ä–µ–∂–µ {n67} {pw} –∏–∑ {k} (67%). –ü—Ä–∏—Ö–æ–¥—è—Ç –Ω–µ —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(2/3)}."
                    if name == "–ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å":
                        return f"–û–±—ä—ë–º < {v33s} –µ–¥. –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ {n33}‚Äì{n67} {pw} –∏–∑ {k} (33‚Äì67%). –ü—Ä–∏—Ö–æ–¥—è—Ç –≤ —Å—Ä–µ–¥–Ω–µ–º –∫–∞–∂–¥—ã–µ {_days(0.5)}‚Äì{_days(1/3)}."
                    if name == "–†–∞–∑–æ–≤–∞—è –ø–æ–∫—É–ø–∫–∞":
                        return f"–û–±—ä—ë–º < {v33s} –µ–¥. –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∂–µ {n33} {pw} –∏–∑ {k} (<33%). –ü—Ä–∏—Ö–æ–¥—è—Ç —Ä–µ–∂–µ —á–µ–º –∫–∞–∂–¥—ã–µ {_days(0.33)} –∏–ª–∏ –æ–¥–Ω–∞ –ø–æ–∫—É–ø–∫–∞."
                    if name == "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏":
                        return "–ù–µ—Ç –ø–æ–∫—É–ø–æ–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –æ–∫–Ω–µ."
                    return ""

                report_cluster_comments = {}
                for _, r in summary.iterrows():
                    cn = r["cluster"]
                    if cn == "–ò—Ç–æ–≥–æ":
                        continue
                    desc_text = CLUSTER_8_DESCRIPTIONS.get(cn, "")
                    crit_text = _criteria_text(cn, v33_val, v67_val, k_int_cluster, is_months)
                    report_cluster_comments[cn] = desc_text + ("\n\n–ö—Ä–∏—Ç–µ—Ä–∏–∏: " + crit_text if crit_text else "")
                st.session_state["report_cluster_comments"] = report_cluster_comments

                cluster_names_list = summary["cluster"].tolist()
                cluster_options = [c for c in cluster_names_list if c != "–ò—Ç–æ–≥–æ"]
                cluster_options_display = [_cluster_display_name(n) for n in cluster_options]
                cluster_display_to_full = {_cluster_display_name(n): n for n in cluster_names_list}
                cluster_full_to_display = {n: _cluster_display_name(n) for n in cluster_names_list}

                desc = CLUSTER_8_DESCRIPTIONS
                col_presence = "–ü—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ"
                col_regularity_2 = "–†–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç—å"

                def _escape_html(s: str) -> str:
                    return (s or "").replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")

                num_columns = 8
                rows_html = []
                for row_idx, r in summary.iterrows():
                    cluster_name = r["cluster"]
                    crit = _criteria_text(cluster_name, v33_val, v67_val, k_int_cluster, is_months)
                    if cluster_name == "–ò—Ç–æ–≥–æ":
                        cell_cluster = "<strong>–ò—Ç–æ–≥–æ</strong>"
                    else:
                        display_name = _cluster_display_name(cluster_name)
                        desc_text = desc.get(cluster_name, "") or ""
                        cell_cluster = (
                            f'<details class="cluster-details-wrap">'
                            f'<summary class="cluster-summary"><span class="cluster-arrow">‚ñ∂</span> {_escape_html(display_name)}</summary>'
                            f"</details>"
                        )
                        details_row_content = (
                            f'<div class="cluster-details">'
                            f'<div class="cluster-details-inner">'
                            f'<div class="cluster-detail-block"><strong>–û–ø–∏—Å–∞–Ω–∏–µ:</strong> {_escape_html(desc_text)}</div>'
                            f'<div class="cluster-detail-block"><strong>–ö—Ä–∏—Ç–µ—Ä–∏–∏:</strong> {_escape_html(crit)}</div>'
                            f"</div></div>"
                        )
                    pct_val = r["pct_fmt"]
                    avg_r = r["avg_regularity"] if pd.notna(r["avg_regularity"]) else 0
                    x_per = round(avg_r * k_int_cluster, 1)
                    y_pct = round(avg_r * 100, 1)
                    line1 = f"{x_per} {period_word_plural} –∏–∑ {k_int_cluster} ({y_pct}%)"
                    if avg_r > 0.001:
                        z_days = max(1, round(days_per_period / avg_r))
                        window_days = k_int_cluster * days_per_period
                        suffix = " (–≤–µ—Ä–æ—è—Ç–Ω–æ —Ä–µ–∂–µ)" if z_days >= window_days else ""
                        line2 = f"–í —Å—Ä–µ–¥–Ω–µ–º –∫–∞–∂–¥—ã–µ {z_days} –¥–Ω.{suffix}"
                    else:
                        line2 = "–ü—Ä–∏—Ö–æ–¥—è—Ç —Ä–µ–¥–∫–æ –∏–ª–∏ –æ–¥–Ω–∞ –ø–æ–∫—É–ø–∫–∞"
                    rows_html.append(
                        f"<tr><td>{cell_cluster}</td>"
                        f"<td>{int(r['clients'])}</td><td>{pct_val}</td>"
                        f"<td>{int(r['total_volume'])}</td><td>{r['pct_volume_fmt']}</td><td>{r['avg_client_per_period']:.2f}</td>"
                        f"<td>{line1}</td><td>{line2}</td></tr>"
                    )
                    if cluster_name != "–ò—Ç–æ–≥–æ":
                        rows_html.append(
                            f'<tr class="cluster-details-row" style="display:none;">'
                            f'<td colspan="{num_columns}">{details_row_content}</td></tr>'
                        )
                thead = (
                    f"<thead><tr>"
                    f"<th>{col_cluster}</th>"
                    f"<th>–ö–ª–∏–µ–Ω—Ç–æ–≤</th><th>% –∫–ª–∏–µ–Ω—Ç–æ–≤</th><th>{col_volume}</th><th>{col_pct_volume}</th><th>{col_avg_client}</th>"
                    f"<th>{col_presence}</th><th>{col_regularity_2}</th>"
                    f"</tr></thead>"
                )
                tbody = "<tbody>" + "".join(rows_html) + "</tbody>"
                cluster_table_html = (
                    "<!DOCTYPE html><html><head><meta charset='utf-8'>"
                    "<style>\n"
                    "html, body { overflow-x: hidden; max-width: 100%; box-sizing: border-box; }\n"
                    "body { font-family: 'Source Sans 3', 'Source Sans Pro', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; font-size: 1rem; margin: 0; padding: 0.5rem; }\n"
                    ".cluster-table-shell { margin: 0.5rem 0; background: #dee2e6; padding: 8px; border-radius: 8px; overflow: hidden; }\n"
                    ".cluster-table-wrap { min-height: 400px; max-height: 85vh; overflow-y: auto; overflow-x: hidden; width: 100%; max-width: 100%; }\n"
                    ".cluster-table { width: 100%; max-width: 100%; table-layout: fixed; border-collapse: collapse; font-size: 0.9375rem; "
                    "border: 1px solid #adb5bd; border-radius: 0; box-shadow: 0 2px 6px rgba(0,0,0,0.06); background: #e2e6ea; }\n"
                    ".cluster-table thead th { position: sticky; top: 0; z-index: 100; box-sizing: border-box; "
                    "background: #343a40; color: #fff; font-weight: 600; padding: 6px 10px; text-align: left; "
                    "font-size: 0.9375rem; box-shadow: 0 2px 2px rgba(0,0,0,0.2); line-height: 1.3; "
                    "word-wrap: break-word; overflow-wrap: break-word; border: 1px solid #adb5bd; }\n"
                    ".cluster-table thead th:nth-child(1) { width: 16%; }\n"
                    ".cluster-table thead th:nth-child(2) { width: 8%; }\n"
                    ".cluster-table thead th:nth-child(3) { width: 8%; }\n"
                    ".cluster-table thead th:nth-child(4) { width: 10%; }\n"
                    ".cluster-table thead th:nth-child(5) { width: 8%; }\n"
                    ".cluster-table thead th:nth-child(6) { width: 12%; }\n"
                    ".cluster-table thead th:nth-child(7) { width: 14%; }\n"
                    ".cluster-table thead th:nth-child(8) { width: 12%; }\n"
                    ".cluster-table thead th:nth-child(9) { width: 12%; }\n"
                    ".cluster-table thead th:nth-child(2), .cluster-table thead th:nth-child(3), .cluster-table thead th:nth-child(4), "
                    ".cluster-table thead th:nth-child(5), .cluster-table thead th:nth-child(6) { text-align: center; }\n"
                    ".cluster-table td { padding: 5px 10px; border: 1px solid #adb5bd; background: #e2e6ea; color: #212529; vertical-align: middle; font-size: 0.9375rem; line-height: 1.35; "
                    "word-wrap: break-word; overflow-wrap: break-word; box-sizing: border-box; }\n"
                    ".cluster-table td:nth-child(1) { font-weight: 500; }\n"
                    ".cluster-table td:nth-child(2), .cluster-table td:nth-child(3), .cluster-table td:nth-child(4), "
                    ".cluster-table td:nth-child(5), .cluster-table td:nth-child(6) { text-align: center; }\n"
                    ".cluster-details-wrap summary { list-style: none; cursor: pointer; font-size: 0.9375rem; line-height: 1.3; }\n"
                    ".cluster-details-wrap summary::-webkit-details-marker { display: none; }\n"
                    ".cluster-arrow { display: inline-block; margin-right: 4px; font-size: 0.7rem; color: #495057; }\n"
                    ".cluster-details-wrap[open] .cluster-arrow { transform: rotate(90deg); }\n"
                    ".cluster-details-row td { padding: 0; border: 1px solid #adb5bd; background: #e2e6ea; vertical-align: top; }\n"
                    ".cluster-details { padding: 12px 16px; margin: 8px 10px; background: #fff; color: #212529; "
                    "border: 1px solid #adb5bd; border-left: 4px solid #495057; border-radius: 6px; font-size: 0.9rem; line-height: 1.5; "
                    "box-shadow: 0 2px 8px rgba(0,0,0,0.08); }\n"
                    ".cluster-details-inner { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem 1.5rem; max-width: 100%; }\n"
                    ".cluster-detail-block { min-width: 0; }\n"
                    ".cluster-detail-block strong { font-weight: 600; font-style: italic; display: block; margin-bottom: 2px; }\n"
                    ".cluster-detail-block:first-child strong { color: #5c2d91; }\n"
                    ".cluster-detail-block:last-child strong { color: #e85d04; }\n"
                    "@media (max-width: 640px) { .cluster-details-inner { grid-template-columns: 1fr; } }\n"
                    ".cluster-table tbody tr:hover td { background-color: #e9ecef; }\n"
                    ".cluster-table tbody tr:first-child td { background: rgba(128, 0, 128, 0.4) !important; color: #fff !important; font-weight: bold; }\n"
                    ".cluster-table tbody tr:first-child:hover td { background: rgba(128, 0, 128, 0.5) !important; }\n"
                    ".cluster-table tbody tr:first-child .cluster-arrow { color: rgba(255,255,255,0.9); }\n"
                    "</style></head><body>"
                    f'<div class="cluster-table-shell"><div class="cluster-table-wrap"><table class="cluster-table">{thead}{tbody}</table></div></div>'
                    "<script>"
                    "document.querySelectorAll('.cluster-details-wrap').forEach(function(d){"
                    "  d.addEventListener('toggle', function(){"
                    "    var tr = this.closest('tr');"
                    "    if(!tr) return;"
                    "    var next = tr.nextElementSibling;"
                    "    if(next && next.classList.contains('cluster-details-row')){"
                    "      next.style.display = this.open ? 'table-row' : 'none';"
                    "    }"
                    "  });"
                    "});"
                    "</script>"
                    "</body></html>"
                )
                components.html(cluster_table_html, height=min(520, 180 + len(rows_html) * 32), scrolling=True)

                # –í—ã–±–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞ (–ø—Ä—è–º–æ –ø–æ–¥ —Ç–∞–±–ª–∏—Ü–µ–π)
                st.markdown("<div style='margin-top: 0.25rem;'></div>", unsafe_allow_html=True)
                col_clusters_sel, col_copy_btn = st.columns([1, 1])
                with col_clusters_sel:
                    selected_clusters_for_copy = st.multiselect(
                        "–í—ã–±–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞",
                        options=cluster_options_display,
                        default=[],
                        key="cluster_copy_multiselect",
                    )
                with col_copy_btn:
                    selected_full_names = [cluster_display_to_full[s] for s in selected_clusters_for_copy if s in cluster_display_to_full]
                    ids_for_copy = per_client[per_client["cluster"].isin(selected_full_names)]["client_id"].tolist()
                    copy_data_str = "\n".join(str(c) for c in ids_for_copy)
                    n_copy = len(ids_for_copy)
                    copy_label = f"üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥—ã ({n_copy})" if n_copy else "üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥—ã (0)"
                    create_copy_button(copy_data_str, copy_label, "copy_cluster_codes")

        # --- –ë–ª–æ–∫ ¬´–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ —è–∫–æ—Ä–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞¬ª (–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Äî –∏–∑ ¬´–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç—á—ë—Ç–∞¬ª, —Ç–æ–ª—å–∫–æ –≤—ã–±–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤) ---
        st.divider()
        st.subheader("–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞ —è–∫–æ—Ä–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞")

        cohort_start_lc = cohort_start_global
        cohort_end_lc = cohort_end_global
        selected_categories_lifecycle = selected_categories_global
        k_periods_lifecycle = k_periods_global

        idx_start_lc = cohort_labels.index(cohort_start_lc)
        idx_end_lc = cohort_labels.index(cohort_end_lc)
        if idx_start_lc <= idx_end_lc:
            cohorts_to_use_lc = cohort_labels[idx_start_lc : idx_end_lc + 1]
        else:
            cohorts_to_use_lc = cohort_labels[idx_end_lc : idx_start_lc + 1]

        st.caption("–û—Ç–±–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –Ω–µ–¥–µ–ª—è–º.")
        cluster_options_only = [_cluster_display_name(c) for c in CLUSTER_8_ORDER] + ["–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"]
        cluster_options_with_all = ["–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"] + cluster_options_only
        if "lifecycle_clusters_selection" not in st.session_state:
            st.session_state["lifecycle_clusters_selection"] = ["–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"]
        if "lifecycle_clusters_multiselect" not in st.session_state:
            st.session_state["lifecycle_clusters_multiselect"] = ["–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"]
        default_lc = st.session_state["lifecycle_clusters_selection"]
        raw_selection = st.multiselect(
            "–ö–ª–∞—Å—Ç–µ—Ä—ã",
            options=cluster_options_with_all,
            default=default_lc,
            key="lifecycle_clusters_multiselect",
            label_visibility="collapsed",
        )
        # –ê–≤—Ç–æ-–ª–æ–≥–∏–∫–∞: –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã –∏ ¬´–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã¬ª, –∏ –¥—Ä—É–≥–∏–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –¥—Ä—É–≥–∏–µ
        if "–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã" in raw_selection and len(raw_selection) > 1:
            selected_clusters_lifecycle = [x for x in raw_selection if x != "–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"]
        else:
            selected_clusters_lifecycle = raw_selection if raw_selection else ["–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"]
        st.session_state["lifecycle_clusters_selection"] = selected_clusters_lifecycle
        if raw_selection != selected_clusters_lifecycle:
            st.session_state["lifecycle_clusters_multiselect"] = selected_clusters_lifecycle
            st.rerun()

        if not cohorts_to_use_lc:
            st.caption("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –∫–æ–≥–æ—Ä—Ç—É.")
        elif not selected_categories_lifecycle:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç.")
        else:
            cohort_clients_lc = set()
            for lb in cohorts_to_use_lc:
                r = cohort_ranks[lb]
                pm, ps = rank_to_period.loc[r, COL_PERIOD_MAIN], rank_to_period.loc[r, COL_PERIOD_SUB]
                pm, ps = str(pm).strip(), str(ps).strip()
                clients_r = df1[
                    (df1[COL_PERIOD_MAIN].astype(str).str.strip() == pm)
                    & (df1[COL_PERIOD_SUB].astype(str).str.strip() == ps)
                ][COL_CLIENT]
                cohort_clients_lc.update(_norm_client_id(clients_r).tolist())

            if not cohort_clients_lc:
                st.info("–í –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–≥–æ—Ä—Ç–∞—Ö –Ω–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ (–ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É 1).")
            else:
                df1_cr_lc = df1_with_period.copy()
                df1_cr_lc["_client_norm"] = _norm_client_id(df1_cr_lc[COL_CLIENT])
                df1_cr_lc = df1_cr_lc[df1_cr_lc["_client_norm"].isin(cohort_clients_lc)]
                client_cohort_rank_lc = df1_cr_lc.groupby("_client_norm")["period_rank"].min()

                k_int_lc = int(k_periods_lifecycle)
                n_anchor_lc = 100  # —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –∏ —Ñ—Ä–∞–∑—ã ¬´–ü—Ä–∏ –ø—Ä–æ–¥–∞–∂–µ ‚Ä¶ –±—É–¥–µ—Ç –ø—Ä–æ–¥–∞–Ω–æ ‚Ä¶¬ª
                client_cohort_rank_dict_lc = client_cohort_rank_lc.to_dict()

                def _in_window_lc(row):
                    c = row.get("_client_norm")
                    r0 = client_cohort_rank_dict_lc.get(c)
                    if r0 is None or pd.isna(r0):
                        return False
                    pr = row.get("period_rank")
                    if pd.isna(pr):
                        return False
                    return r0 <= pr < r0 + k_int_lc

                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø–æ–∫—É–ø–∫–∏ –ø–æ –∫–æ–≥–æ—Ä—Ç–µ ‚Äî –Ω—É–∂–Ω—ã –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                anchor_cats = set(categories_from_doc1)
                analyzable_list = list(selected_categories_lifecycle)
                other_cats = set(all_categories) - anchor_cats - set(analyzable_list)

                df1_lc = df1_with_period[df1_with_period["_client_norm"].isin(cohort_clients_lc)][
                    ["_client_norm", "period_rank", COL_CATEGORY, COL_QUANTITY]
                ].copy()
                df2_lc = df2_with_period[df2_with_period["_client_norm"].isin(cohort_clients_lc)][
                    ["_client_norm", "period_rank", COL_CATEGORY, COL_QUANTITY]
                ].copy()
                df_purchases_lc = pd.concat([df1_lc.rename(columns={"_client_norm": "client_id"}), df2_lc.rename(columns={"_client_norm": "client_id"})], ignore_index=True)

                def _to_set(x):
                    return x if isinstance(x, set) else set()

                client_period_cats = (
                    df_purchases_lc.groupby(["client_id", "period_rank"])[COL_CATEGORY]
                    .apply(lambda s: set(s.dropna().unique().tolist()))
                    .reset_index()
                    .rename(columns={COL_CATEGORY: "categories"})
                )

                # –ö–ª–∞—Å—Ç–µ—Ä—ã –ø–æ –æ–±—ä—ë–º—É –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –≤ –æ–∫–Ω–µ K
                per_client_lc = pd.DataFrame({"client_id": sorted(cohort_clients_lc)})
                per_client_lc["cohort_rank"] = per_client_lc["client_id"].map(client_cohort_rank_lc).astype(float)
                df_analyzable_lc = df_purchases_lc[df_purchases_lc[COL_CATEGORY].isin(analyzable_list)].copy()
                df_analyzable_lc = df_analyzable_lc.merge(per_client_lc[["client_id", "cohort_rank"]], on="client_id", how="inner")
                df_analyzable_lc["_in_window"] = (df_analyzable_lc["period_rank"] >= df_analyzable_lc["cohort_rank"]) & (df_analyzable_lc["period_rank"] < df_analyzable_lc["cohort_rank"] + k_int_lc)
                df_analyzable_lc = df_analyzable_lc[df_analyzable_lc["_in_window"]]
                if not df_analyzable_lc.empty:
                    agg_lc = (
                        df_analyzable_lc.groupby("client_id")
                        .agg(volume=(COL_QUANTITY, "sum"), active_periods=("period_rank", "nunique"))
                        .reset_index()
                    )
                    per_client_lc = per_client_lc.merge(agg_lc, on="client_id", how="left")
                if "volume" not in per_client_lc.columns:
                    per_client_lc["volume"] = 0
                else:
                    per_client_lc["volume"] = per_client_lc["volume"].fillna(0).astype(int)
                if "active_periods" not in per_client_lc.columns:
                    per_client_lc["active_periods"] = 0
                else:
                    per_client_lc["active_periods"] = per_client_lc["active_periods"].fillna(0).astype(int)
                per_client_lc["regularity"] = (per_client_lc["active_periods"] / k_int_lc).clip(0, 1).astype(float)
                per_client_lc["cluster"] = "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"
                df_fit_lc = per_client_lc[per_client_lc["volume"] > 0].copy()
                if not df_fit_lc.empty:
                    v33_lc = float(df_fit_lc["volume"].quantile(1 / 3))
                    v67_lc = float(df_fit_lc["volume"].quantile(2 / 3))
                    r33, r67 = 1 / 3, 2 / 3

                    def _assign_cluster_lc(row):
                        v, r = row["volume"], row["regularity"]
                        if v >= v67_lc:
                            if r >= r67:
                                return "–ê–∫—Ç–∏–≤–Ω—ã–µ (VIP)"
                            if r >= r33:
                                return "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º"
                            return "–†–∞–∑–æ–≤–∞—è –∫—Ä—É–ø–Ω–∞—è –ø–æ–∫—É–ø–∫–∞"
                        if v >= v33_lc:
                            if r >= r67:
                                return "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                            if r >= r33:
                                return "–°—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                            return "–ö—Ä—É–ø–Ω—ã–µ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ"
                        if r >= r67:
                            return "–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (–º–∞–ª—ã–π –æ–±—ä—ë–º)"
                        if r >= r33:
                            return "–ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
                        return "–†–∞–∑–æ–≤–∞—è –ø–æ–∫—É–ø–∫–∞"

                    df_fit_lc["cluster"] = df_fit_lc.apply(_assign_cluster_lc, axis=1)
                    per_client_lc = per_client_lc.merge(df_fit_lc[["client_id", "cluster"]], on="client_id", how="left", suffixes=("", "_fit"))
                    per_client_lc["cluster"] = per_client_lc["cluster_fit"].fillna(per_client_lc["cluster"])
                    per_client_lc = per_client_lc.drop(columns=["cluster_fit"], errors="ignore")

                display_to_full_lc = {_cluster_display_name(c): c for c in CLUSTER_8_ORDER}
                display_to_full_lc["–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"] = "–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"
                if "–í—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã" in selected_clusters_lifecycle or not selected_clusters_lifecycle:
                    selected_cluster_set = set(CLUSTER_8_ORDER + ["–ù–µ –ø–æ–∫—É–ø–∞–ª–∏"])
                else:
                    selected_cluster_set = set(display_to_full_lc.get(s, s) for s in selected_clusters_lifecycle)
                cohort_clients_filtered = set(per_client_lc[per_client_lc["cluster"].isin(selected_cluster_set)]["client_id"].tolist())

                # –ü—Ä–æ–¥–∞–∂–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –Ω–∞ –æ–±—ä—ë–º —è–∫–æ—Ä–Ω–æ–≥–æ ‚Äî —Ç–æ–ª—å–∫–æ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Ç–µ—Ä–∞–º
                df1_anchor_lc = df1_with_period.copy()
                df1_anchor_lc["_client_norm"] = _norm_client_id(df1_anchor_lc[COL_CLIENT])
                df1_anchor_lc = df1_anchor_lc[df1_anchor_lc["_client_norm"].isin(cohort_clients_filtered)]
                df1_anchor_lc["_in_window"] = df1_anchor_lc.apply(_in_window_lc, axis=1)
                q_anchor_lc = df1_anchor_lc.loc[df1_anchor_lc["_in_window"], COL_QUANTITY].sum()

                selected_in_doc1_lc = [c for c in selected_categories_lifecycle if c in categories_from_doc1_set]
                selected_in_doc2_lc = [c for c in selected_categories_lifecycle if c in set(categories_from_doc2)]
                parts_an_lc = []
                if selected_in_doc1_lc:
                    d1_lc = df1_with_period[df1_with_period[COL_CATEGORY].isin(selected_in_doc1_lc)].copy()
                    d1_lc["_client_norm"] = _norm_client_id(d1_lc[COL_CLIENT])
                    d1_lc = d1_lc[d1_lc["_client_norm"].isin(cohort_clients_filtered)]
                    d1_lc["_in_window"] = d1_lc.apply(_in_window_lc, axis=1)
                    parts_an_lc.append(d1_lc.loc[d1_lc["_in_window"], [COL_CATEGORY, COL_QUANTITY]])
                if selected_in_doc2_lc:
                    d2_lc = df2_with_period[df2_with_period[COL_CATEGORY].isin(selected_in_doc2_lc)].copy()
                    d2_lc["_client_norm"] = _norm_client_id(d2_lc[COL_CLIENT])
                    d2_lc = d2_lc[d2_lc["_client_norm"].isin(cohort_clients_filtered)]
                    d2_lc["_in_window"] = d2_lc.apply(_in_window_lc, axis=1)
                    parts_an_lc.append(d2_lc.loc[d2_lc["_in_window"], [COL_CATEGORY, COL_QUANTITY]])
                if parts_an_lc:
                    df_an_lc = pd.concat(parts_an_lc, ignore_index=True)
                    q_by_cat_lc = df_an_lc.groupby(COL_CATEGORY)[COL_QUANTITY].sum().reindex(selected_categories_lifecycle).fillna(0).astype(int)
                else:
                    q_by_cat_lc = pd.Series(dtype=int)
                q_analyzed_lc = int(q_by_cat_lc.sum()) if len(q_by_cat_lc) else 0

                if not cohort_clients_filtered:
                    sales_section_html = (
                        f'<span class="block-block-title">–ü—Ä–æ–¥–∞–∂–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –æ–±—ä—ë–º —è–∫–æ—Ä–Ω–æ–≥–æ</span>'
                        f'<p class="block-p">–í –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö –Ω–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.</p>'
                    )
                elif q_anchor_lc and q_anchor_lc > 0:
                    r_ratio_lc = q_analyzed_lc / q_anchor_lc
                    expected_int_lc = int(round(n_anchor_lc * r_ratio_lc))
                    period_range_caption_sales = format_period_range_for_caption(
                        cohorts_to_use_lc, cohort_ranks, rank_to_period, k_periods_lifecycle, is_months
                    )
                    analyzed_names_lc = (
                        selected_categories_lifecycle[0]
                        if len(selected_categories_lifecycle) == 1
                        else ", ".join(selected_categories_lifecycle)
                    )
                    anchor_esc_lc = category_label.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                    analyzable_esc_lc = analyzed_names_lc.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                    sales_section_html = (
                        f'<span class="block-block-title">–ü—Ä–æ–¥–∞–∂–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –æ–±—ä—ë–º —è–∫–æ—Ä–Ω–æ–≥–æ</span>'
                        f'<p class="block-p">–û–±—ä—ë–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É —è–∫–æ—Ä–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞: <span class="block-num">{r_ratio_lc:.2f}</span>.</p>'
                    )
                else:
                    sales_section_html = (
                        f'<span class="block-block-title">–ü—Ä–æ–¥–∞–∂–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –æ–±—ä—ë–º —è–∫–æ—Ä–Ω–æ–≥–æ</span>'
                        f'<p class="block-p">–í –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö –∏ –ø–µ—Ä–∏–æ–¥–µ –Ω–µ—Ç –ø–æ–∫—É–ø–æ–∫ —è–∫–æ—Ä–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω.</p>'
                    )

                # –°–µ—Ç–∫–∞ ¬´–∫–ª–∏–µ–Ω—Ç √ó –ø–µ—Ä–∏–æ–¥¬ª –∏ —Ñ–ª–∞–≥–∏ –ø–æ–∫—É–ø–æ–∫ (–¥–ª—è —Ç–∞–±–ª–∏—Ü—ã –∏ —Ç–µ–∫—Å—Ç–∞ ¬´–¶–∏–∫–ª –∂–∏–∑–Ω–∏¬ª)
                client_weeks = []
                for c in cohort_clients_lc:
                    r0 = client_cohort_rank_lc.get(c)
                    if r0 is None or pd.isna(r0):
                        continue
                    r0 = int(r0)
                    for t in range(k_int_lc):
                        client_weeks.append({"client_id": c, "t": t, "period_rank": r0 + t})
                df_cw = pd.DataFrame(client_weeks)
                df_cw = df_cw.merge(client_period_cats, on=["client_id", "period_rank"], how="left")
                df_cw["categories"] = df_cw["categories"].apply(_to_set)

                df_cw["bought_anchor"] = df_cw["categories"].apply(lambda s: bool(s & anchor_cats))
                for i, cat in enumerate(analyzable_list):
                    df_cw[f"bought_a{i}"] = df_cw["categories"].apply(lambda s, c=cat: c in s)
                df_cw["bought_other"] = df_cw["categories"].apply(lambda s: bool(s & other_cats))
                df_cw["no_purchase"] = df_cw["categories"].apply(lambda s: len(s) == 0)
                if analyzable_list:
                    df_cw["bought_any_analyzable"] = df_cw[[f"bought_a{i}" for i in range(len(analyzable_list))]].any(axis=1)
                else:
                    df_cw["bought_any_analyzable"] = False

                df_cw = df_cw[df_cw["client_id"].isin(cohort_clients_filtered)]

                N_lc = len(cohort_clients_filtered)
                if N_lc == 0:
                    st.warning("–í –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö –Ω–µ—Ç –∫–ª–∏–µ–Ω—Ç–æ–≤. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –∏–ª–∏ –∫–æ–≥–æ—Ä—Ç—ã.")
                else:
                    agg_d = {"bought_anchor": ("bought_anchor", "sum"), "bought_other": ("bought_other", "sum"), "no_purchase": ("no_purchase", "sum"), "bought_any_analyzable": ("bought_any_analyzable", "sum")}
                    for i in range(len(analyzable_list)):
                        agg_d[f"bought_a{i}"] = (f"bought_a{i}", "sum")
                    summary_by_week = df_cw.groupby("t").agg(**agg_d).reset_index()

                    half_life_week = None
                    pct_before_half = None
                    pct_at_half = None
                    for _, r in summary_by_week.iterrows():
                        if r["bought_any_analyzable"] / N_lc < 0.5:
                            half_life_week = int(r["t"])
                            pct_at_half = 100 * r["bought_any_analyzable"] / N_lc
                            row_before = summary_by_week[summary_by_week["t"] == half_life_week - 1]
                            pct_before_half = 100 * row_before.iloc[0]["bought_any_analyzable"] / N_lc if half_life_week > 0 and not row_before.empty else None
                            break
                    df_cw_sorted = df_cw.sort_values(["client_id", "t"])
                    first_miss = df_cw_sorted[df_cw_sorted["bought_any_analyzable"] == False].groupby("client_id")["t"].min().reset_index().rename(columns={"t": "first_miss"})
                    clients_all = df_cw_sorted["client_id"].unique()
                    consec = pd.DataFrame({"client_id": clients_all}).merge(first_miss, on="client_id", how="left")
                    consec["consecutive_weeks"] = consec["first_miss"].fillna(k_int_lc).astype(int)
                    avg_consecutive_weeks = consec["consecutive_weeks"].mean() if len(consec) else 0.0
                    median_consecutive_weeks = consec["consecutive_weeks"].median() if len(consec) else 0.0

                    gap_lengths = []
                    for cid in df_cw["client_id"].unique():
                        seq = df_cw[df_cw["client_id"] == cid].set_index("t").reindex(range(k_int_lc)).fillna(False)["bought_any_analyzable"].tolist()
                        i = 0
                        while i < k_int_lc:
                            if not seq[i]:
                                j = i
                                while j < k_int_lc and not seq[j]:
                                    j += 1
                                gap_lengths.append(j - i)
                                i = j
                            else:
                                i += 1
                    median_gap = float(np.median(gap_lengths)) if gap_lengths else 1.0
                    sustained_threshold = max(1, int(round(median_gap)))
                    first_sustained_start = {}
                    first_sustained_other = {}
                    first_sustained_none = {}
                    for cid in df_cw["client_id"].unique():
                        rows = df_cw[df_cw["client_id"] == cid].sort_values("t")
                        seq = rows.set_index("t").reindex(range(k_int_lc)).fillna(False)["bought_any_analyzable"].tolist()
                        i = 0
                        found = None
                        while i < k_int_lc:
                            if not seq[i]:
                                j = i
                                while j < k_int_lc and not seq[j]:
                                    j += 1
                                if (j - i) >= sustained_threshold:
                                    found = (i, j - i)
                                    break
                                i = j
                            else:
                                i += 1
                        if found is not None:
                            t_start, gap_len = found
                            first_sustained_start[cid] = t_start
                            window = df_cw[(df_cw["client_id"] == cid) & (df_cw["t"] >= t_start) & (df_cw["t"] < t_start + gap_len)]
                            first_sustained_other[cid] = window["bought_other"].any()
                            first_sustained_none[cid] = window["no_purchase"].any()
                    n_sustained = len(first_sustained_start)
                    avg_first_sustained_week = np.mean(list(first_sustained_start.values())) if first_sustained_start else None
                    pct_in_gap_other = 100 * sum(first_sustained_other.values()) / n_sustained if n_sustained else 0
                    pct_in_gap_none = 100 * sum(first_sustained_none.values()) / n_sustained if n_sustained else 0
                    pct_clients_with_sustained = 100 * n_sustained / N_lc if N_lc else 0

                    last_purchase_week = df_cw[df_cw["bought_any_analyzable"]].groupby("client_id")["t"].max()
                    last_pw = last_purchase_week.reindex(consec["client_id"].values)
                    last_pw.index = consec.index
                    exited_mask = (last_pw < k_int_lc - 1) | last_pw.isna()
                    exited_clients = consec.loc[exited_mask]["client_id"].tolist()
                    pct_exited = 100 * len(exited_clients) / N_lc if N_lc else 0
                    avg_last_purchase_week = last_pw.loc[exited_mask].dropna().mean() if exited_mask.any() else None

                    t_mid = (k_int_lc - 1) // 2
                    mid_rows = summary_by_week[summary_by_week["t"] == t_mid]
                    row_mid = mid_rows.iloc[0] if len(mid_rows) else None
                    row_0 = summary_by_week[summary_by_week["t"] == 0].iloc[0] if len(summary_by_week[summary_by_week["t"] == 0]) else None
                    pct_anchor_mid = 100 * row_mid["bought_anchor"] / N_lc if row_mid is not None else (100 * row_0["bought_anchor"] / N_lc if row_0 is not None else 0)
                    pct_analyzable_mid = 100 * row_mid["bought_any_analyzable"] / N_lc if row_mid is not None and analyzable_list else None
                    pct_analyzable_first = 100 * row_0["bought_any_analyzable"] / N_lc if analyzable_list and row_0 is not None else None

                    n_last_weeks = min(3, k_int_lc)
                    t_end_from = k_int_lc - n_last_weeks + 1
                    t_end_to = k_int_lc

                    df_last_week = df_cw[df_cw["t"] == k_int_lc - 1]
                    df_last_n = df_cw[df_cw["t"] >= k_int_lc - n_last_weeks]
                    other_cat_count = {}
                    for _, r in df_last_week.iterrows():
                        for c in (r["categories"] & other_cats):
                            other_cat_count[c] = other_cat_count.get(c, 0) + 1
                    most_popular_other = max(other_cat_count, key=other_cat_count.get) if other_cat_count else None
                    pct_most_popular_other = 100 * other_cat_count.get(most_popular_other, 0) / N_lc if most_popular_other else 0.0

                    client_other_cats_n = {}
                    for _, r in df_last_n.iterrows():
                        if r["bought_other"] and r["categories"] & other_cats:
                            for c in (r["categories"] & other_cats):
                                client_other_cats_n.setdefault(r["client_id"], set()).add(c)
                    other_clients_count_n = {}
                    for cid, cats in client_other_cats_n.items():
                        for c in cats:
                            other_clients_count_n[c] = other_clients_count_n.get(c, set()) | {cid}
                    top3_other = sorted(
                        [(c, len(s)) for c, s in other_clients_count_n.items()],
                        key=lambda x: -x[1]
                    )[:3]
                    top3_other_pct = [(c, 100 * cnt / N_lc) for c, cnt in top3_other] if N_lc else []

                    no_purchase_per_client_n = df_last_n.groupby("client_id")["no_purchase"].all()
                    clients_all_weeks_in_window = df_last_n.groupby("client_id").size() == n_last_weeks
                    clients_none_last_n = (no_purchase_per_client_n & clients_all_weeks_in_window).sum()
                    pct_none_last_n = 100 * clients_none_last_n / N_lc if N_lc else 0.0
                    clients_other_last_n = df_last_n[df_last_n["bought_other"]]["client_id"].nunique()
                    pct_other_last_n = 100 * clients_other_last_n / N_lc if N_lc else 0.0

                    period_unit_lc = "–º–µ—Å—è—Ü" if is_months else "–Ω–µ–¥–µ–ª—è"
                    period_unit_plural = "–º–µ—Å—è—Ü–µ–≤" if is_months else "–Ω–µ–¥–µ–ª—å"
                    period_unit_single = "–Ω–µ–¥–µ–ª—è" if not is_months else "–º–µ—Å—è—Ü"
                    if is_months:
                        n_last_word = "–º–µ—Å—è—Ü" if n_last_weeks == 1 else ("–º–µ—Å—è—Ü–∞" if n_last_weeks <= 4 else "–º–µ—Å—è—Ü–µ–≤")
                    else:
                        n_last_word = "–Ω–µ–¥–µ–ª—é" if n_last_weeks == 1 else ("–Ω–µ–¥–µ–ª–∏" if n_last_weeks <= 4 else "–Ω–µ–¥–µ–ª—å")
                    end_period_weeks_str = f"{period_unit_single} {t_end_from}‚Äì{t_end_to}" if n_last_weeks > 1 else f"{period_unit_single} {t_end_to}"

                    table_rows = []
                    for _, row in summary_by_week.iterrows():
                        t = int(row["t"])
                        cells = [str(t)]
                        cells.append(f"{int(row['bought_anchor'])} ({100 * row['bought_anchor'] / N_lc:.1f}%)")
                        for i in range(len(analyzable_list)):
                            cells.append(f"{int(row[f'bought_a{i}'])} ({100 * row[f'bought_a{i}'] / N_lc:.1f}%)")
                        cells.append(f"{int(row['bought_other'])} ({100 * row['bought_other'] / N_lc:.1f}%)")
                        cells.append(f"{int(row['no_purchase'])} ({100 * row['no_purchase'] / N_lc:.1f}%)")
                        table_rows.append(cells)

                    col_headers = ["–ù–µ–¥–µ–ª—è/–º–µ—Å—è—Ü –æ—Ç –∫–æ–≥–æ—Ä—Ç—ã", "–ü–æ–∫—É–ø–∞—é—Ç —è–∫–æ—Ä–Ω—ã–π"]
                    col_headers.extend([f"–ü–æ–∫—É–ø–∞—é—Ç {c}" for c in analyzable_list])
                    col_headers.extend(["–ü–æ–∫—É–ø–∞—é—Ç –ø—Ä–æ—á–∏–µ", "–ù–µ—Ç –ø–æ–∫—É–ø–æ–∫"])

                    df_display = pd.DataFrame(table_rows, columns=col_headers)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)

                    last = summary_by_week.iloc[-1]
                    pct_anchor_last = 100 * last["bought_anchor"] / N_lc
                    pct_other_last = 100 * last["bought_other"] / N_lc
                    pct_none_last = 100 * last["no_purchase"] / N_lc
                    pct_analyzable_last = [100 * last[f"bought_a{i}"] / N_lc for i in range(len(analyzable_list))]
                    first_row = summary_by_week.iloc[0]
                    pct_anchor_first = 100 * first_row["bought_anchor"] / N_lc

                    period_range_caption_lc = format_period_range_for_caption(
                        cohorts_to_use_lc, cohort_ranks, rank_to_period, k_periods_lifecycle, is_months
                    )
                    period_word_until = "–Ω–µ–¥–µ–ª–∏" if not is_months else "–º–µ—Å—è—Ü–∞"
                    period_word_on = "–Ω–µ–¥–µ–ª–µ" if not is_months else "–º–µ—Å—è—Ü–µ"
                    analyzable_names_esc = ", ".join([c.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;") for c in analyzable_list])
                    if half_life_week is not None and pct_at_half is not None:
                        pct_bef = f"{pct_before_half:.1f}%" if pct_before_half is not None else "‚Äî"
                        half_life_text = (
                            f"–î–æ–ª—è –ø–æ–∫—É–ø–∞—é—â–∏—Ö –ª—é–±–æ–π –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (<span class=\"block-product\">{analyzable_names_esc}</span>) –ø–∞–¥–∞–µ—Ç –Ω–∏–∂–µ 50% –Ω–∞—á–∏–Ω–∞—è —Å {period_word_until} <span class=\"block-num\">{half_life_week}</span> "
                            f"(–Ω–∞ {period_word_on} <span class=\"block-num\">{half_life_week - 1}</span> ‚Äî <span class=\"block-num\">{pct_bef}</span>, "
                            f"–Ω–∞ {period_word_on} <span class=\"block-num\">{half_life_week}</span> ‚Äî <span class=\"block-num\">{pct_at_half:.1f}%</span>)."
                        )
                    elif half_life_week is not None:
                        half_life_text = (
                            f"–î–æ–ª—è –ø–æ–∫—É–ø–∞—é—â–∏—Ö –ª—é–±–æ–π –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (<span class=\"block-product\">{analyzable_names_esc}</span>) –ø–∞–¥–∞–µ—Ç –Ω–∏–∂–µ 50% –Ω–∞—á–∏–Ω–∞—è —Å {period_word_until} <span class=\"block-num\">{half_life_week}</span> "
                            f"(–Ω–∞ {period_word_on} <span class=\"block-num\">{half_life_week}</span> ‚Äî <span class=\"block-num\">{pct_at_half:.1f}%</span>)."
                        )
                    else:
                        half_life_text = f"–ù–∞ –≤—Å—ë–º –ø–µ—Ä–∏–æ–¥–µ (<span class=\"block-num\">{k_int_lc}</span> {period_unit_plural}) –±–æ–ª–µ–µ –ø–æ–ª–æ–≤–∏–Ω—ã –∫–æ–≥–æ—Ä—Ç—ã –ø–æ–∫—É–ø–∞—é—Ç —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (<span class=\"block-product\">{analyzable_names_esc}</span>)."

                    anchor_name_esc = category_label.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                    week_1 = 1
                    week_mid = t_mid + 1
                    week_end = k_int_lc
                    cohort_short_names = [lb.split(" (")[0] for lb in cohorts_to_use_lc]
                    if len(cohort_short_names) == 1:
                        cohorts_list_str = cohort_short_names[0]
                    else:
                        cohorts_list_str = f"{cohort_short_names[0]}-{cohort_short_names[-1]}"
                    n_c = len(cohorts_to_use_lc)
                    if n_c % 10 == 1 and n_c != 11:
                        cohort_word = "–∫–æ–≥–æ—Ä—Ç–∞"
                    elif n_c % 10 in (2, 3, 4) and n_c not in (12, 13, 14):
                        cohort_word = "–∫–æ–≥–æ—Ä—Ç—ã"
                    else:
                        cohort_word = "–∫–æ–≥–æ—Ä—Ç"
                    header_first_line = (
                        f"{period_range_caption_lc}; <span class=\"block-num\">{n_c}</span> {cohort_word} (<span class=\"block-product\">{cohorts_list_str}</span>); "
                        f"<span class=\"block-num\">{N_lc}</span> –∫–ª–∏–µ–Ω—Ç–æ–≤; –ü–µ—Ä–≤—ã–µ <span class=\"block-num\">{k_int_lc}</span> {period_unit_plural} —Å –º–æ–º–µ–Ω—Ç–∞ –∫–æ–≥–æ—Ä—Ç—ã."
                    )
                    p1_anchor_body = (
                        f"–î–æ–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤, –ø–æ–∫—É–ø–∞—é—â–∏—Ö —è–∫–æ—Ä–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç <span class=\"block-product\">{anchor_name_esc}</span>: "
                        f"–≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞ ({period_unit_single} <span class=\"block-num\">{week_1}</span>) ‚Äî <span class=\"block-num\">{pct_anchor_first:.1f}%</span>, "
                        f"–≤ —Å–µ—Ä–µ–¥–∏–Ω–µ ({period_unit_single} <span class=\"block-num\">{week_mid}</span>) ‚Äî <span class=\"block-num\">{pct_anchor_mid:.1f}%</span>, "
                        f"–∫ –∫–æ–Ω—Ü—É ({period_unit_single} <span class=\"block-num\">{week_end}</span>) ‚Äî <span class=\"block-num\">{pct_anchor_last:.1f}%</span>."
                    )
                    p2_analyzable_parts = []
                    if analyzable_list:
                        p2_analyzable_parts.append(
                            f"–î–æ–ª—è –ø–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º –ø—Ä–æ–¥—É–∫—Ç–∞–º –∫ –∫–æ–Ω—Ü—É –ø–µ—Ä–∏–æ–¥–∞ ({period_unit_single} <span class=\"block-num\">{week_end}</span>): "
                            + ", ".join([f"<span class=\"block-product\">{c.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')}</span> ‚Äî <span class=\"block-num\">{pct_analyzable_last[i]:.1f}%</span>" for i, c in enumerate(analyzable_list)])
                            + ". "
                        )
                        if pct_analyzable_first is not None and pct_analyzable_mid is not None:
                            pct_analyzable_end_overall = 100 * last["bought_any_analyzable"] / N_lc
                            p2_analyzable_parts.append(
                                f"–î–æ–ª—è –ø–æ–∫—É–ø–∞—é—â–∏—Ö –ª—é–±–æ–π –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–æ–±—â–∞–∫–æ–º) —Å–Ω–∏–∂–∞–µ—Ç—Å—è –≤ —Ç—Ä–∏ —ç—Ç–∞–ø–∞: –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞ ({period_unit_single} <span class=\"block-num\">{week_1}</span>) ‚Äî <span class=\"block-num\">{pct_analyzable_first:.1f}%</span>, "
                                f"–≤ —Å–µ—Ä–µ–¥–∏–Ω–µ ({period_unit_single} <span class=\"block-num\">{week_mid}</span>) ‚Äî <span class=\"block-num\">{pct_analyzable_mid:.1f}%</span>, –∫ –∫–æ–Ω—Ü—É ({period_unit_single} <span class=\"block-num\">{week_end}</span>) ‚Äî <span class=\"block-num\">{pct_analyzable_end_overall:.1f}%</span>. "
                            )
                        for i, c in enumerate(analyzable_list):
                            c_esc = c.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                            first_i = 100 * row_0[f"bought_a{i}"] / N_lc if row_0 is not None else None
                            mid_i = 100 * row_mid[f"bought_a{i}"] / N_lc if row_mid is not None else None
                            last_i = pct_analyzable_last[i]
                            if first_i is not None and mid_i is not None:
                                p2_analyzable_parts.append(
                                    f"–ü–æ –ø—Ä–æ–¥—É–∫—Ç—É <span class=\"block-product\">{c_esc}</span>: –≤ –Ω–∞—á–∞–ª–µ ‚Äî <span class=\"block-num\">{first_i:.1f}%</span>, –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ ‚Äî <span class=\"block-num\">{mid_i:.1f}%</span>, –∫ –∫–æ–Ω—Ü—É ‚Äî <span class=\"block-num\">{last_i:.1f}%</span>. "
                                )
                    p2_analyzable_html = " ".join(p2_analyzable_parts) if p2_analyzable_parts else ""
                    p2_outcomes_html = (
                        f"–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ <span class=\"block-num\">{n_last_weeks}</span> {n_last_word} ({end_period_weeks_str}): "
                        f"<span class=\"block-num\">{pct_other_last_n:.1f}%</span> –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ–∫—É–ø–∞–ª–∏ –ø—Ä–æ—á–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–±–µ–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞), "
                        f"<span class=\"block-num\">{pct_none_last_n:.1f}%</span> –Ω–µ –∏–º–µ–ª–∏ –ø–æ–∫—É–ø–æ–∫ (–Ω–∏ —è–∫–æ—Ä–Ω–æ–≥–æ, –Ω–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ, –Ω–∏ –ø—Ä–æ—á–∏—Ö) –Ω–∏ –≤ –æ–¥–Ω—É –∏–∑ —ç—Ç–∏—Ö {period_unit_plural}."
                    )
                    p2_other_popular_html = ""
                    if top3_other_pct:
                        top3_parts = []
                        for c, pct in top3_other_pct:
                            c_esc = c.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                            top3_parts.append(f"<span class=\"block-product\">{c_esc}</span> ‚Äî <span class=\"block-num\">{pct:.1f}%</span> –∫–æ–≥–æ—Ä—Ç—ã")
                        p2_other_popular_html = (
                            f"–°—Ä–µ–¥–∏ –ø—Ä–æ—á–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ <span class=\"block-num\">{n_last_weeks}</span> {n_last_word} ({end_period_weeks_str}) —Ç–æ–ø-3: "
                            + "; ".join(top3_parts) + "."
                        )
                    p3_html = half_life_text
                    period_loc = "–Ω–µ–¥–µ–ª–µ" if not is_months else "–º–µ—Å—è—Ü–µ"
                    period_loc_gen = "–Ω–µ–¥–µ–ª–∏" if not is_months else "–º–µ—Å—è—Ü–∞"
                    period_one = "–æ–¥–Ω–∞ –Ω–µ–¥–µ–ª—è" if not is_months else "–æ–¥–∏–Ω –º–µ—Å—è—Ü"
                    p4_parts = []
                    if analyzable_list:
                        p4_parts.append(
                            f"–í –∫–æ–≥–æ—Ä—Ç–µ —Ç–∏–ø–∏—á–Ω—ã–π –ø–µ—Ä–µ—Ä—ã–≤ –º–µ–∂–¥—É –ø–æ–∫—É–ø–∫–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ ‚Äî <span class=\"block-num\">{median_gap:.1f}</span> {period_unit_plural} (–º–µ–¥–∏–∞–Ω–∞ –ø–æ –≤—Å–µ–º –ø–µ—Ä–µ—Ä—ã–≤–∞–º). "
                        )
                        if n_sustained > 0 and avg_first_sustained_week is not None:
                            pct_rest = 100 - pct_in_gap_other
                            p4_parts.append(
                                f"–ü–µ—Ä–≤—ã–π —É—Å—Ç–æ–π—á–∏–≤—ã–π –ø–µ—Ä–µ—Ä—ã–≤ –±–æ–ª–µ–µ <span class=\"block-num\">{sustained_threshold}</span> {period_loc_gen} –µ—Å—Ç—å —É <span class=\"block-num\">{pct_clients_with_sustained:.1f}%</span> –∫–æ–≥–æ—Ä—Ç—ã; –≤ —Å—Ä–µ–¥–Ω–µ–º –æ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ {period_loc} <span class=\"block-num\">{avg_first_sustained_week:.1f}</span>. "
                                f"–í —ç—Ç–æ–º –ø–µ—Ä–µ—Ä—ã–≤–µ —É <span class=\"block-num\">{pct_in_gap_none:.1f}%</span> –∫–ª–∏–µ–Ω—Ç–æ–≤ –±—ã–ª–∞ —Ö–æ—Ç—è –±—ã {period_one} –±–µ–∑ –ø–æ–∫—É–ø–æ–∫ –≤–æ–æ–±—â–µ (–Ω–∏ —è–∫–æ—Ä–Ω–æ–≥–æ, –Ω–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ, –Ω–∏ –ø—Ä–æ—á–∏—Ö); —É <span class=\"block-num\">{pct_in_gap_other:.1f}%</span> ‚Äî —Ö–æ—Ç—è –±—ã {period_one} —Å –ø–æ–∫—É–ø–∫–∞–º–∏ –ø—Ä–æ—á–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π (—É –æ—Å—Ç–∞–ª—å–Ω—ã—Ö <span class=\"block-num\">{pct_rest:.1f}%</span> –≤ –ø–µ—Ä–µ—Ä—ã–≤–µ –ø—Ä–æ—á–∏–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª–∏). "
                            )
                        p4_parts.append(
                            f"–ü–æ–ª–Ω—ã–π —É—Ö–æ–¥ –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞: <span class=\"block-num\">{pct_exited:.1f}%</span> –∫–æ–≥–æ—Ä—Ç—ã"
                        )
                        if avg_last_purchase_week is not None and not np.isnan(avg_last_purchase_week):
                            p4_parts.append(f"; –≤ —Å—Ä–µ–¥–Ω–µ–º –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∫—É–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ –Ω–∞ {period_loc} <span class=\"block-num\">{avg_last_purchase_week:.1f}</span>. ")
                        else:
                            p4_parts.append(". ")
                    p4_html = "".join(p4_parts) if p4_parts else ""

                    lifecycle_box_css = (
                        "<style>"
                        ".block-result-box { background: #343a40; border: 1px solid #dee2e6; border-radius: 8px; padding: 1rem 1.25rem; margin: 0.5rem 0; color: white; }"
                        ".block-result-box .block-period-caption { font-weight: 600; letter-spacing: 0.02em; padding-bottom: 0.4rem; margin-bottom: 0; display: block; }"
                        ".block-result-box .block-divider { border-top: 1px solid rgba(255,255,255,0.35); margin: 0.75rem 0; }"
                        ".block-result-box .block-block-title { font-size: 1.05rem; font-weight: 700; color: rgba(255,255,255,0.98); display: block; margin-bottom: 0.5rem; padding-bottom: 0.35rem; border-bottom: 2px solid rgba(255,255,255,0.4); background: rgba(0,0,0,0.15); padding: 0.5rem 0.6rem; border-radius: 6px; margin-top: 0; }"
                        ".block-result-box .block-block-title:first-of-type { margin-top: 0; }"
                        ".block-result-box .block-section-title { font-weight: 600; margin-top: 0.75rem; margin-bottom: 0.25rem; color: rgba(255,255,255,0.95); display: block; font-size: 0.95rem; }"
                        ".block-result-box .block-section-title:first-of-type { margin-top: 0; }"
                        ".block-result-box .block-num { color: #e85d04; font-size: 1.25rem; font-weight: bold; }"
                        ".block-result-box .block-product { font-style: italic; background: rgba(255, 255, 255, 0.1); color: rgba(255, 255, 255, 0.95); padding: 0.1em 0.35em; border-radius: 4px; }"
                        ".block-result-box p.block-p { margin: 0 0 0.5rem 0; font-size: 1rem; line-height: 1.4; }"
                        "</style>"
                    )
                    # –û–¥–∏–Ω –±–æ–ª—å—à–æ–π —Å–µ—Ä—ã–π –±–ª–æ–∫: –ø–µ—Ä–∏–æ–¥, –ø—Ä–æ–¥–∞–∂–∏, —Ñ—Ä–∞–∑–∞ ¬´–ü—Ä–∏ –ø—Ä–æ–¥–∞–∂–µ 100 –µ–¥. ‚Ä¶¬ª, —Ü–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞
                    lifecycle_box_html = (
                        lifecycle_box_css
                        + f'<div class="block-result-box">'
                        + f'<span class="block-period-caption">{header_first_line}</span>'
                        + f'<div class="block-divider"></div>'
                        + sales_section_html
                    )
                    if q_anchor_lc and q_anchor_lc > 0:
                        lifecycle_box_html += (
                            f'<p class="block-p">–ü—Ä–∏ –ø—Ä–æ–¥–∞–∂–µ <span class="block-num">{n_anchor_lc}</span> –µ–¥. <span class="block-product">{anchor_esc_lc}</span> –≤ —Ç–µ—á–µ–Ω–∏–∏ '
                            f'<span class="block-num">{k_periods_lifecycle}</span> {period_word} –±—É–¥–µ—Ç –ø—Ä–æ–¥–∞–Ω–æ '
                            f'<span class="block-num">{expected_int_lc}</span> –µ–¥. <span class="block-product">{analyzable_esc_lc}</span>.</p>'
                        )
                    lifecycle_box_html += (
                        f'<div class="block-divider"></div>'
                        + f'<span class="block-block-title">–¶–∏–∫–ª –∂–∏–∑–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞</span>'
                        + f'<span class="block-section-title">–Ø–∫–æ—Ä–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç</span>'
                        + f'<p class="block-p">{p1_anchor_body}</p>'
                    )
                    if p2_analyzable_html:
                        lifecycle_box_html += f'<span class="block-section-title">–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π –ø—Ä–æ–¥—É–∫—Ç</span><p class="block-p">{p2_analyzable_html}</p>'
                    lifecycle_box_html += (
                        f'<span class="block-section-title">–ò—Å—Ö–æ–¥—ã –∫ –∫–æ–Ω—Ü—É –ø–µ—Ä–∏–æ–¥–∞ ({end_period_weeks_str})</span>'
                        + f'<p class="block-p">{p2_outcomes_html}</p>'
                    )
                    if p2_other_popular_html:
                        lifecycle_box_html += f'<span class="block-section-title">–°—Ä–µ–¥–∏ –ø—Ä–æ—á–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π</span><p class="block-p">{p2_other_popular_html}</p>'
                    lifecycle_box_html += (
                        f'<span class="block-section-title">–ü–æ–ª—É—Ä–∞—Å–ø–∞–¥ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞</span>'
                        + f'<p class="block-p">{p3_html}</p>'
                    )
                    if p4_html:
                        lifecycle_box_html += f'<span class="block-section-title">–£—Å—Ç–æ–π—á–∏–≤—ã–π –ø–µ—Ä–µ—Ä—ã–≤ –∏ —É—Ö–æ–¥ –∏–∑ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞</span><p class="block-p">{p4_html}</p>'
                    lifecycle_box_html += "</div>"

                    st.markdown(lifecycle_box_html, unsafe_allow_html=True)

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –≤ Excel –¥–ª—è –∫–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤ –±–ª–æ–∫–µ ¬´–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç—á—ë—Ç–∞¬ª
                    cluster_summary_for_excel = st.session_state.get("report_cluster_summary")
                    cluster_comments_for_excel = st.session_state.get("report_cluster_comments", {})
                    html_without_css = _strip_css_from_html(lifecycle_box_html)
                    lifecycle_text = _html_to_plain_text(html_without_css)
                    safe_filename = "CLF " + re.sub(r'[*\\/:?"<>|]', "_", category_label) + ".xlsx"
                    st.session_state["excel_report_filename"] = safe_filename
                    try:
                        excel_bytes = build_excel_report(
                            cohort_start=cohort_start_global,
                            cohort_end=cohort_end_global,
                            categories=selected_categories_global,
                            k_periods=int(k_periods_global),
                            is_months=is_months,
                            cluster_summary=cluster_summary_for_excel,
                            cluster_comments=cluster_comments_for_excel,
                            lifecycle_clusters=selected_clusters_lifecycle,
                            lifecycle_table=df_display,
                            lifecycle_output_text=lifecycle_text,
                        )
                        st.session_state["excel_report_bytes"] = excel_bytes
                        if not had_excel_bytes:
                            st.rerun()
                    except Exception:
                        st.session_state["excel_report_bytes"] = None

    else:
        st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ø–æ —à–∞–±–ª–æ–Ω—É (5 —Å—Ç–æ–ª–±—Ü–æ–≤: –∫–∞—Ç–µ–≥–æ—Ä–∏—è, –ø–µ—Ä–∏–æ–¥, –ø–µ—Ä–∏–æ–¥, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –∫–æ–¥ –∫–ª–∏–µ–Ω—Ç–∞).")
